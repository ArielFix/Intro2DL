{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArielFix/Intro2DL/blob/OnGoingAssignment1/Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bhfIKbQzGq2"
      },
      "source": [
        "# Assignment 1. Music Century Classification\n",
        "\n",
        "**Assignment Responsible**: Natalie Lang.\n",
        "\n",
        "In this assignment, we will build models to predict which\n",
        "**century** a piece of music was released.  We will be using the \"YearPredictionMSD Data Set\"\n",
        "based on the Million Song Dataset. The data is available to download from the UCI \n",
        "Machine Learning Repository. Here are some links about the data:\n",
        "\n",
        "- https://archive.ics.uci.edu/ml/datasets/yearpredictionmsd\n",
        "- http://millionsongdataset.com/pages/tasks-demos/#yearrecognition\n",
        "\n",
        "Note that you are note allowed to import additional packages **(especially not PyTorch)**. One of the objectives is to understand how the training procedure actually operates, before working with PyTorch's autograd engine which does it all for us.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47oq1vy5PUIV"
      },
      "source": [
        "## Question 1. Data (21%)\n",
        "\n",
        "Start by setting up a Google Colab notebook in which to do your work.\n",
        "Since you are working with a partner, you might find this link helpful:\n",
        "\n",
        "- https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb\n",
        "\n",
        "The recommended way to work together is pair coding, where you and your partner are sitting together and writing code together. \n",
        "\n",
        "To process and read the data, we use the popular `pandas` package for data analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aFWpuNSzGq9"
      },
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7UWL6mFzGq-"
      },
      "source": [
        "Now that your notebook is set up, we can load the data into the notebook. The code below provides\n",
        "two ways of loading the data: directly from the internet, or through mounting Google Drive.\n",
        "The first method is easier but slower, and the second method is a bit involved at first, but\n",
        "can save you time later on. You will need to mount Google Drive for later assignments, so we recommend\n",
        "figuring how to do that now.\n",
        "\n",
        "Here are some resources to help you get started:\n",
        "\n",
        "- http.://colab.research.google.com/notebooks/io.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY6PrfV4zGq_",
        "outputId": "f859bb38-d42c-4da9-e008-feb2a59c147b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "load_from_drive = True\n",
        "\n",
        "if not load_from_drive:\n",
        "  csv_path = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip\"\n",
        "else:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  csv_path = '/content/gdrive/My Drive/MSc/Courses/Into to Deep Learnig/Assignments/YearPredictionMSD.txt.zip' # TODO - UPDATE ME WITH THE TRUE PATH!\n",
        "\n",
        "t_label = [\"year\"]\n",
        "x_labels = [\"var%d\" % i for i in range(1, 91)]\n",
        "df = pandas.read_csv(csv_path, names=t_label + x_labels)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgB83beNzGq_"
      },
      "source": [
        "Now that the data is loaded to your Colab notebook, you should be able to display the Pandas\n",
        "DataFrame `df` as a table:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5bBEnj3zGq_",
        "outputId": "3289fad9-ada2-43ca-ca8a-ada566dcdeb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        year      var1      var2      var3      var4      var5      var6  \\\n",
              "0       2001  49.94357  21.47114  73.07750   8.74861 -17.40628 -13.09905   \n",
              "1       2001  48.73215  18.42930  70.32679  12.94636 -10.32437 -24.83777   \n",
              "2       2001  50.95714  31.85602  55.81851  13.41693  -6.57898 -18.54940   \n",
              "3       2001  48.24750  -1.89837  36.29772   2.58776   0.97170 -26.21683   \n",
              "4       2001  50.97020  42.20998  67.09964   8.46791 -15.85279 -16.81409   \n",
              "...      ...       ...       ...       ...       ...       ...       ...   \n",
              "515340  2006  51.28467  45.88068  22.19582  -5.53319  -3.61835 -16.36914   \n",
              "515341  2006  49.87870  37.93125  18.65987  -3.63581 -27.75665 -18.52988   \n",
              "515342  2006  45.12852  12.65758 -38.72018   8.80882 -29.29985  -2.28706   \n",
              "515343  2006  44.16614  32.38368  -3.34971  -2.49165 -19.59278 -18.67098   \n",
              "515344  2005  51.85726  59.11655  26.39436  -5.46030 -20.69012 -19.95528   \n",
              "\n",
              "            var7      var8      var9  ...     var81      var82      var83  \\\n",
              "0      -25.01202 -12.23257   7.83089  ...  13.01620  -54.40548   58.99367   \n",
              "1        8.76630  -0.92019  18.76548  ...   5.66812  -19.68073   33.04964   \n",
              "2       -3.27872  -2.35035  16.07017  ...   3.03800   26.05866  -50.92779   \n",
              "3        5.05097 -10.34124   3.55005  ...  34.57337 -171.70734  -16.96705   \n",
              "4      -12.48207  -9.37636  12.63699  ...   9.92661  -55.95724   64.92712   \n",
              "...          ...       ...       ...  ...       ...        ...        ...   \n",
              "515340   2.12652   5.18160  -8.66890  ...   4.81440   -3.75991  -30.92584   \n",
              "515341   7.76108   3.56109  -2.50351  ...  32.38589  -32.75535  -61.05473   \n",
              "515342 -18.40424 -22.28726  -4.52429  ... -18.73598  -71.15954 -123.98443   \n",
              "515343   8.78428   4.02039 -12.01230  ...  67.16763  282.77624   -4.63677   \n",
              "515344  -6.72771   2.29590  10.31018  ... -11.50511  -69.18291   60.58456   \n",
              "\n",
              "            var84     var85     var86      var87     var88      var89  \\\n",
              "0        15.37344   1.11144 -23.08793   68.40795  -1.82223  -27.46348   \n",
              "1        42.87836  -9.90378 -32.22788   70.49388  12.04941   58.43453   \n",
              "2        10.93792  -0.07568  43.20130 -115.00698  -0.05859   39.67068   \n",
              "3       -46.67617 -12.51516  82.58061  -72.08993   9.90558  199.62971   \n",
              "4       -17.72522  -1.49237  -7.50035   51.76631   7.88713   55.66926   \n",
              "...           ...       ...       ...        ...       ...        ...   \n",
              "515340   26.33968  -5.03390  21.86037 -142.29410   3.42901  -41.14721   \n",
              "515341   56.65182  15.29965  95.88193  -10.63242  12.96552   92.11633   \n",
              "515342  121.26989  10.89629  34.62409 -248.61020  -6.07171   53.96319   \n",
              "515343  144.00125  21.62652 -29.72432   71.47198  20.32240   14.83107   \n",
              "515344   28.64599  -4.39620 -64.56491  -45.61012  -5.51512   32.35602   \n",
              "\n",
              "           var90  \n",
              "0        2.26327  \n",
              "1       26.92061  \n",
              "2       -0.66345  \n",
              "3       18.85382  \n",
              "4       28.74903  \n",
              "...          ...  \n",
              "515340 -15.46052  \n",
              "515341  10.88815  \n",
              "515342  -8.09364  \n",
              "515343  39.74909  \n",
              "515344  12.17352  \n",
              "\n",
              "[515345 rows x 91 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ec64d16-d735-46d1-99f1-a1a95548f313\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>var1</th>\n",
              "      <th>var2</th>\n",
              "      <th>var3</th>\n",
              "      <th>var4</th>\n",
              "      <th>var5</th>\n",
              "      <th>var6</th>\n",
              "      <th>var7</th>\n",
              "      <th>var8</th>\n",
              "      <th>var9</th>\n",
              "      <th>...</th>\n",
              "      <th>var81</th>\n",
              "      <th>var82</th>\n",
              "      <th>var83</th>\n",
              "      <th>var84</th>\n",
              "      <th>var85</th>\n",
              "      <th>var86</th>\n",
              "      <th>var87</th>\n",
              "      <th>var88</th>\n",
              "      <th>var89</th>\n",
              "      <th>var90</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>49.94357</td>\n",
              "      <td>21.47114</td>\n",
              "      <td>73.07750</td>\n",
              "      <td>8.74861</td>\n",
              "      <td>-17.40628</td>\n",
              "      <td>-13.09905</td>\n",
              "      <td>-25.01202</td>\n",
              "      <td>-12.23257</td>\n",
              "      <td>7.83089</td>\n",
              "      <td>...</td>\n",
              "      <td>13.01620</td>\n",
              "      <td>-54.40548</td>\n",
              "      <td>58.99367</td>\n",
              "      <td>15.37344</td>\n",
              "      <td>1.11144</td>\n",
              "      <td>-23.08793</td>\n",
              "      <td>68.40795</td>\n",
              "      <td>-1.82223</td>\n",
              "      <td>-27.46348</td>\n",
              "      <td>2.26327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.73215</td>\n",
              "      <td>18.42930</td>\n",
              "      <td>70.32679</td>\n",
              "      <td>12.94636</td>\n",
              "      <td>-10.32437</td>\n",
              "      <td>-24.83777</td>\n",
              "      <td>8.76630</td>\n",
              "      <td>-0.92019</td>\n",
              "      <td>18.76548</td>\n",
              "      <td>...</td>\n",
              "      <td>5.66812</td>\n",
              "      <td>-19.68073</td>\n",
              "      <td>33.04964</td>\n",
              "      <td>42.87836</td>\n",
              "      <td>-9.90378</td>\n",
              "      <td>-32.22788</td>\n",
              "      <td>70.49388</td>\n",
              "      <td>12.04941</td>\n",
              "      <td>58.43453</td>\n",
              "      <td>26.92061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.95714</td>\n",
              "      <td>31.85602</td>\n",
              "      <td>55.81851</td>\n",
              "      <td>13.41693</td>\n",
              "      <td>-6.57898</td>\n",
              "      <td>-18.54940</td>\n",
              "      <td>-3.27872</td>\n",
              "      <td>-2.35035</td>\n",
              "      <td>16.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>3.03800</td>\n",
              "      <td>26.05866</td>\n",
              "      <td>-50.92779</td>\n",
              "      <td>10.93792</td>\n",
              "      <td>-0.07568</td>\n",
              "      <td>43.20130</td>\n",
              "      <td>-115.00698</td>\n",
              "      <td>-0.05859</td>\n",
              "      <td>39.67068</td>\n",
              "      <td>-0.66345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.24750</td>\n",
              "      <td>-1.89837</td>\n",
              "      <td>36.29772</td>\n",
              "      <td>2.58776</td>\n",
              "      <td>0.97170</td>\n",
              "      <td>-26.21683</td>\n",
              "      <td>5.05097</td>\n",
              "      <td>-10.34124</td>\n",
              "      <td>3.55005</td>\n",
              "      <td>...</td>\n",
              "      <td>34.57337</td>\n",
              "      <td>-171.70734</td>\n",
              "      <td>-16.96705</td>\n",
              "      <td>-46.67617</td>\n",
              "      <td>-12.51516</td>\n",
              "      <td>82.58061</td>\n",
              "      <td>-72.08993</td>\n",
              "      <td>9.90558</td>\n",
              "      <td>199.62971</td>\n",
              "      <td>18.85382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.97020</td>\n",
              "      <td>42.20998</td>\n",
              "      <td>67.09964</td>\n",
              "      <td>8.46791</td>\n",
              "      <td>-15.85279</td>\n",
              "      <td>-16.81409</td>\n",
              "      <td>-12.48207</td>\n",
              "      <td>-9.37636</td>\n",
              "      <td>12.63699</td>\n",
              "      <td>...</td>\n",
              "      <td>9.92661</td>\n",
              "      <td>-55.95724</td>\n",
              "      <td>64.92712</td>\n",
              "      <td>-17.72522</td>\n",
              "      <td>-1.49237</td>\n",
              "      <td>-7.50035</td>\n",
              "      <td>51.76631</td>\n",
              "      <td>7.88713</td>\n",
              "      <td>55.66926</td>\n",
              "      <td>28.74903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515340</th>\n",
              "      <td>2006</td>\n",
              "      <td>51.28467</td>\n",
              "      <td>45.88068</td>\n",
              "      <td>22.19582</td>\n",
              "      <td>-5.53319</td>\n",
              "      <td>-3.61835</td>\n",
              "      <td>-16.36914</td>\n",
              "      <td>2.12652</td>\n",
              "      <td>5.18160</td>\n",
              "      <td>-8.66890</td>\n",
              "      <td>...</td>\n",
              "      <td>4.81440</td>\n",
              "      <td>-3.75991</td>\n",
              "      <td>-30.92584</td>\n",
              "      <td>26.33968</td>\n",
              "      <td>-5.03390</td>\n",
              "      <td>21.86037</td>\n",
              "      <td>-142.29410</td>\n",
              "      <td>3.42901</td>\n",
              "      <td>-41.14721</td>\n",
              "      <td>-15.46052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515341</th>\n",
              "      <td>2006</td>\n",
              "      <td>49.87870</td>\n",
              "      <td>37.93125</td>\n",
              "      <td>18.65987</td>\n",
              "      <td>-3.63581</td>\n",
              "      <td>-27.75665</td>\n",
              "      <td>-18.52988</td>\n",
              "      <td>7.76108</td>\n",
              "      <td>3.56109</td>\n",
              "      <td>-2.50351</td>\n",
              "      <td>...</td>\n",
              "      <td>32.38589</td>\n",
              "      <td>-32.75535</td>\n",
              "      <td>-61.05473</td>\n",
              "      <td>56.65182</td>\n",
              "      <td>15.29965</td>\n",
              "      <td>95.88193</td>\n",
              "      <td>-10.63242</td>\n",
              "      <td>12.96552</td>\n",
              "      <td>92.11633</td>\n",
              "      <td>10.88815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515342</th>\n",
              "      <td>2006</td>\n",
              "      <td>45.12852</td>\n",
              "      <td>12.65758</td>\n",
              "      <td>-38.72018</td>\n",
              "      <td>8.80882</td>\n",
              "      <td>-29.29985</td>\n",
              "      <td>-2.28706</td>\n",
              "      <td>-18.40424</td>\n",
              "      <td>-22.28726</td>\n",
              "      <td>-4.52429</td>\n",
              "      <td>...</td>\n",
              "      <td>-18.73598</td>\n",
              "      <td>-71.15954</td>\n",
              "      <td>-123.98443</td>\n",
              "      <td>121.26989</td>\n",
              "      <td>10.89629</td>\n",
              "      <td>34.62409</td>\n",
              "      <td>-248.61020</td>\n",
              "      <td>-6.07171</td>\n",
              "      <td>53.96319</td>\n",
              "      <td>-8.09364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515343</th>\n",
              "      <td>2006</td>\n",
              "      <td>44.16614</td>\n",
              "      <td>32.38368</td>\n",
              "      <td>-3.34971</td>\n",
              "      <td>-2.49165</td>\n",
              "      <td>-19.59278</td>\n",
              "      <td>-18.67098</td>\n",
              "      <td>8.78428</td>\n",
              "      <td>4.02039</td>\n",
              "      <td>-12.01230</td>\n",
              "      <td>...</td>\n",
              "      <td>67.16763</td>\n",
              "      <td>282.77624</td>\n",
              "      <td>-4.63677</td>\n",
              "      <td>144.00125</td>\n",
              "      <td>21.62652</td>\n",
              "      <td>-29.72432</td>\n",
              "      <td>71.47198</td>\n",
              "      <td>20.32240</td>\n",
              "      <td>14.83107</td>\n",
              "      <td>39.74909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515344</th>\n",
              "      <td>2005</td>\n",
              "      <td>51.85726</td>\n",
              "      <td>59.11655</td>\n",
              "      <td>26.39436</td>\n",
              "      <td>-5.46030</td>\n",
              "      <td>-20.69012</td>\n",
              "      <td>-19.95528</td>\n",
              "      <td>-6.72771</td>\n",
              "      <td>2.29590</td>\n",
              "      <td>10.31018</td>\n",
              "      <td>...</td>\n",
              "      <td>-11.50511</td>\n",
              "      <td>-69.18291</td>\n",
              "      <td>60.58456</td>\n",
              "      <td>28.64599</td>\n",
              "      <td>-4.39620</td>\n",
              "      <td>-64.56491</td>\n",
              "      <td>-45.61012</td>\n",
              "      <td>-5.51512</td>\n",
              "      <td>32.35602</td>\n",
              "      <td>12.17352</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>515345 rows × 91 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ec64d16-d735-46d1-99f1-a1a95548f313')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6ec64d16-d735-46d1-99f1-a1a95548f313 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6ec64d16-d735-46d1-99f1-a1a95548f313');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaLuAMH_zGrA"
      },
      "source": [
        "To set up our data for classification, we'll use the \"year\" field to represent\n",
        "whether a song was released in the 20-th century. In our case `df[\"year\"]` will be 1 if\n",
        "the year was released after 2000, and 0 otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZdGlNgdzGrA"
      },
      "source": [
        "df[\"year\"] = df[\"year\"].map(lambda x: int(x > 2000))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xugy7FZ8eoAd",
        "outputId": "9422226d-0186-43b4-cac9-d484531dd08a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        }
      },
      "source": [
        "df.head(20)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    year      var1       var2      var3      var4      var5      var6  \\\n",
              "0      1  49.94357   21.47114  73.07750   8.74861 -17.40628 -13.09905   \n",
              "1      1  48.73215   18.42930  70.32679  12.94636 -10.32437 -24.83777   \n",
              "2      1  50.95714   31.85602  55.81851  13.41693  -6.57898 -18.54940   \n",
              "3      1  48.24750   -1.89837  36.29772   2.58776   0.97170 -26.21683   \n",
              "4      1  50.97020   42.20998  67.09964   8.46791 -15.85279 -16.81409   \n",
              "5      1  50.54767    0.31568  92.35066  22.38696 -25.51870 -19.04928   \n",
              "6      1  50.57546   33.17843  50.53517  11.55217 -27.24764  -8.78206   \n",
              "7      1  48.26892    8.97526  75.23158  24.04945 -16.02105 -14.09491   \n",
              "8      1  49.75468   33.99581  56.73846   2.89581  -2.92429 -26.44413   \n",
              "9      1  45.17809   46.34234 -40.65357  -2.47909   1.21253  -0.65302   \n",
              "10     1  39.13076  -23.01763 -36.20583   1.67519  -4.27101  13.01158   \n",
              "11     1  37.66498  -34.05910 -17.36060 -26.77781 -39.95119 -20.75000   \n",
              "12     1  26.51957 -148.15762 -13.30095  -7.25851  17.22029 -21.99439   \n",
              "13     1  37.68491  -26.84185 -27.10566 -14.95883  -5.87200 -21.68979   \n",
              "14     0  39.11695   -8.29767 -51.37966  -4.42668 -30.06506 -11.95916   \n",
              "15     1  35.05129  -67.97714 -14.20239  -6.68696  -0.61230 -18.70341   \n",
              "16     1  33.63129  -96.14912 -89.38216 -12.11699  13.77252  -6.69377   \n",
              "17     0  41.38639  -20.78665  51.80155  17.21415 -36.44189 -11.53169   \n",
              "18     0  37.45034   11.42615  56.28982  19.58426 -16.43530   2.22457   \n",
              "19     0  39.71092   -4.92800  12.88590 -11.87773   2.48031 -16.11028   \n",
              "\n",
              "        var7      var8      var9  ...     var81      var82      var83  \\\n",
              "0  -25.01202 -12.23257   7.83089  ...  13.01620  -54.40548   58.99367   \n",
              "1    8.76630  -0.92019  18.76548  ...   5.66812  -19.68073   33.04964   \n",
              "2   -3.27872  -2.35035  16.07017  ...   3.03800   26.05866  -50.92779   \n",
              "3    5.05097 -10.34124   3.55005  ...  34.57337 -171.70734  -16.96705   \n",
              "4  -12.48207  -9.37636  12.63699  ...   9.92661  -55.95724   64.92712   \n",
              "5   20.67345  -5.19943   3.63566  ...   6.59753  -50.69577   26.02574   \n",
              "6  -12.04282  -9.53930  28.61811  ...  11.63681   25.44182  134.62382   \n",
              "7    8.11871  -1.87566   7.46701  ...  18.03989  -58.46192  -65.56438   \n",
              "8    1.71392  -0.55644  22.08594  ...  18.70812    5.20391  -27.75192   \n",
              "9   -6.95536 -12.20040  17.02512  ...  -4.36742  -87.55285  -70.79677   \n",
              "10   8.05718  -8.41088   6.27370  ...  32.86051  -26.08461 -186.82429   \n",
              "11  -0.10231  -0.89972  -1.30205  ...  11.18909   45.20614   53.83925   \n",
              "12   5.51947   3.48418   2.61738  ...  23.80442  251.76360   18.81642   \n",
              "13   4.87374 -18.01800   1.52141  ... -67.57637  234.27192  -72.34557   \n",
              "14  -0.85322  -8.86179  11.36680  ...  42.22923  478.26580  -10.33823   \n",
              "15  -1.31928  -9.46370   5.53492  ...  10.25585   94.90539   15.95689   \n",
              "16 -33.36843 -24.81437  21.22757  ...  49.93249  -14.47489   40.70590   \n",
              "17  11.75252  -7.62428  -3.65488  ...  50.37614  -40.48205   48.07805   \n",
              "18   1.02668  -7.34736  -0.01184  ... -22.46207  -25.77228 -322.42841   \n",
              "19 -16.40421  -8.29657   9.86817  ...  11.92816  -73.72412   16.19039   \n",
              "\n",
              "        var84     var85      var86      var87     var88       var89     var90  \n",
              "0    15.37344   1.11144  -23.08793   68.40795  -1.82223   -27.46348   2.26327  \n",
              "1    42.87836  -9.90378  -32.22788   70.49388  12.04941    58.43453  26.92061  \n",
              "2    10.93792  -0.07568   43.20130 -115.00698  -0.05859    39.67068  -0.66345  \n",
              "3   -46.67617 -12.51516   82.58061  -72.08993   9.90558   199.62971  18.85382  \n",
              "4   -17.72522  -1.49237   -7.50035   51.76631   7.88713    55.66926  28.74903  \n",
              "5    18.94430  -0.33730    6.09352   35.18381   5.00283   -11.02257   0.02263  \n",
              "6    21.51982   8.17570   35.46251   11.57736   4.50056    -4.62739   1.40192  \n",
              "7    46.99856  -4.09602   56.37650  -18.29975  -0.30633     3.98364  -3.72556  \n",
              "8    17.22100  -0.85210  -15.67150  -26.36257   5.48708    -9.13495   6.08680  \n",
              "9    76.57355  -7.71727    3.26926 -298.49845  11.49326   -89.21804 -15.09719  \n",
              "10  113.58176   9.28727   44.60282  158.00425  -2.59543   109.19723  23.36143  \n",
              "11    2.59467  -4.00958  -47.74886 -170.92864  -5.19009     8.83617  -7.16056  \n",
              "12  157.09656 -27.79449 -137.72740  115.28414  23.00230  -164.02536  51.54138  \n",
              "13 -362.25101 -25.55019  -89.08971 -891.58937  14.11648 -1030.99180  99.28967  \n",
              "14 -103.76858  39.19511  -98.76636 -122.81061  -2.14942  -211.48202 -12.81569  \n",
              "15  -98.15732  -9.64859  -93.52834  -95.82981  20.73063  -562.07671  43.44696  \n",
              "16   58.63692   8.81522   27.28474    5.78046   3.44539   259.10825  10.28525  \n",
              "17   -7.62399   6.51934  -30.46090  -53.87264   4.44627    58.16913  -0.02409  \n",
              "18 -146.57408  13.61588   92.22918 -439.80259  25.73235   157.22967  38.70617  \n",
              "19    9.79606   9.71693   -9.90907  -20.65851   2.34002   -31.57015   1.58400  \n",
              "\n",
              "[20 rows x 91 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-695d2b2e-c986-4a39-83c5-fa65f8184433\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>var1</th>\n",
              "      <th>var2</th>\n",
              "      <th>var3</th>\n",
              "      <th>var4</th>\n",
              "      <th>var5</th>\n",
              "      <th>var6</th>\n",
              "      <th>var7</th>\n",
              "      <th>var8</th>\n",
              "      <th>var9</th>\n",
              "      <th>...</th>\n",
              "      <th>var81</th>\n",
              "      <th>var82</th>\n",
              "      <th>var83</th>\n",
              "      <th>var84</th>\n",
              "      <th>var85</th>\n",
              "      <th>var86</th>\n",
              "      <th>var87</th>\n",
              "      <th>var88</th>\n",
              "      <th>var89</th>\n",
              "      <th>var90</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>49.94357</td>\n",
              "      <td>21.47114</td>\n",
              "      <td>73.07750</td>\n",
              "      <td>8.74861</td>\n",
              "      <td>-17.40628</td>\n",
              "      <td>-13.09905</td>\n",
              "      <td>-25.01202</td>\n",
              "      <td>-12.23257</td>\n",
              "      <td>7.83089</td>\n",
              "      <td>...</td>\n",
              "      <td>13.01620</td>\n",
              "      <td>-54.40548</td>\n",
              "      <td>58.99367</td>\n",
              "      <td>15.37344</td>\n",
              "      <td>1.11144</td>\n",
              "      <td>-23.08793</td>\n",
              "      <td>68.40795</td>\n",
              "      <td>-1.82223</td>\n",
              "      <td>-27.46348</td>\n",
              "      <td>2.26327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>48.73215</td>\n",
              "      <td>18.42930</td>\n",
              "      <td>70.32679</td>\n",
              "      <td>12.94636</td>\n",
              "      <td>-10.32437</td>\n",
              "      <td>-24.83777</td>\n",
              "      <td>8.76630</td>\n",
              "      <td>-0.92019</td>\n",
              "      <td>18.76548</td>\n",
              "      <td>...</td>\n",
              "      <td>5.66812</td>\n",
              "      <td>-19.68073</td>\n",
              "      <td>33.04964</td>\n",
              "      <td>42.87836</td>\n",
              "      <td>-9.90378</td>\n",
              "      <td>-32.22788</td>\n",
              "      <td>70.49388</td>\n",
              "      <td>12.04941</td>\n",
              "      <td>58.43453</td>\n",
              "      <td>26.92061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>50.95714</td>\n",
              "      <td>31.85602</td>\n",
              "      <td>55.81851</td>\n",
              "      <td>13.41693</td>\n",
              "      <td>-6.57898</td>\n",
              "      <td>-18.54940</td>\n",
              "      <td>-3.27872</td>\n",
              "      <td>-2.35035</td>\n",
              "      <td>16.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>3.03800</td>\n",
              "      <td>26.05866</td>\n",
              "      <td>-50.92779</td>\n",
              "      <td>10.93792</td>\n",
              "      <td>-0.07568</td>\n",
              "      <td>43.20130</td>\n",
              "      <td>-115.00698</td>\n",
              "      <td>-0.05859</td>\n",
              "      <td>39.67068</td>\n",
              "      <td>-0.66345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>48.24750</td>\n",
              "      <td>-1.89837</td>\n",
              "      <td>36.29772</td>\n",
              "      <td>2.58776</td>\n",
              "      <td>0.97170</td>\n",
              "      <td>-26.21683</td>\n",
              "      <td>5.05097</td>\n",
              "      <td>-10.34124</td>\n",
              "      <td>3.55005</td>\n",
              "      <td>...</td>\n",
              "      <td>34.57337</td>\n",
              "      <td>-171.70734</td>\n",
              "      <td>-16.96705</td>\n",
              "      <td>-46.67617</td>\n",
              "      <td>-12.51516</td>\n",
              "      <td>82.58061</td>\n",
              "      <td>-72.08993</td>\n",
              "      <td>9.90558</td>\n",
              "      <td>199.62971</td>\n",
              "      <td>18.85382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50.97020</td>\n",
              "      <td>42.20998</td>\n",
              "      <td>67.09964</td>\n",
              "      <td>8.46791</td>\n",
              "      <td>-15.85279</td>\n",
              "      <td>-16.81409</td>\n",
              "      <td>-12.48207</td>\n",
              "      <td>-9.37636</td>\n",
              "      <td>12.63699</td>\n",
              "      <td>...</td>\n",
              "      <td>9.92661</td>\n",
              "      <td>-55.95724</td>\n",
              "      <td>64.92712</td>\n",
              "      <td>-17.72522</td>\n",
              "      <td>-1.49237</td>\n",
              "      <td>-7.50035</td>\n",
              "      <td>51.76631</td>\n",
              "      <td>7.88713</td>\n",
              "      <td>55.66926</td>\n",
              "      <td>28.74903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>50.54767</td>\n",
              "      <td>0.31568</td>\n",
              "      <td>92.35066</td>\n",
              "      <td>22.38696</td>\n",
              "      <td>-25.51870</td>\n",
              "      <td>-19.04928</td>\n",
              "      <td>20.67345</td>\n",
              "      <td>-5.19943</td>\n",
              "      <td>3.63566</td>\n",
              "      <td>...</td>\n",
              "      <td>6.59753</td>\n",
              "      <td>-50.69577</td>\n",
              "      <td>26.02574</td>\n",
              "      <td>18.94430</td>\n",
              "      <td>-0.33730</td>\n",
              "      <td>6.09352</td>\n",
              "      <td>35.18381</td>\n",
              "      <td>5.00283</td>\n",
              "      <td>-11.02257</td>\n",
              "      <td>0.02263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>50.57546</td>\n",
              "      <td>33.17843</td>\n",
              "      <td>50.53517</td>\n",
              "      <td>11.55217</td>\n",
              "      <td>-27.24764</td>\n",
              "      <td>-8.78206</td>\n",
              "      <td>-12.04282</td>\n",
              "      <td>-9.53930</td>\n",
              "      <td>28.61811</td>\n",
              "      <td>...</td>\n",
              "      <td>11.63681</td>\n",
              "      <td>25.44182</td>\n",
              "      <td>134.62382</td>\n",
              "      <td>21.51982</td>\n",
              "      <td>8.17570</td>\n",
              "      <td>35.46251</td>\n",
              "      <td>11.57736</td>\n",
              "      <td>4.50056</td>\n",
              "      <td>-4.62739</td>\n",
              "      <td>1.40192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>48.26892</td>\n",
              "      <td>8.97526</td>\n",
              "      <td>75.23158</td>\n",
              "      <td>24.04945</td>\n",
              "      <td>-16.02105</td>\n",
              "      <td>-14.09491</td>\n",
              "      <td>8.11871</td>\n",
              "      <td>-1.87566</td>\n",
              "      <td>7.46701</td>\n",
              "      <td>...</td>\n",
              "      <td>18.03989</td>\n",
              "      <td>-58.46192</td>\n",
              "      <td>-65.56438</td>\n",
              "      <td>46.99856</td>\n",
              "      <td>-4.09602</td>\n",
              "      <td>56.37650</td>\n",
              "      <td>-18.29975</td>\n",
              "      <td>-0.30633</td>\n",
              "      <td>3.98364</td>\n",
              "      <td>-3.72556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>49.75468</td>\n",
              "      <td>33.99581</td>\n",
              "      <td>56.73846</td>\n",
              "      <td>2.89581</td>\n",
              "      <td>-2.92429</td>\n",
              "      <td>-26.44413</td>\n",
              "      <td>1.71392</td>\n",
              "      <td>-0.55644</td>\n",
              "      <td>22.08594</td>\n",
              "      <td>...</td>\n",
              "      <td>18.70812</td>\n",
              "      <td>5.20391</td>\n",
              "      <td>-27.75192</td>\n",
              "      <td>17.22100</td>\n",
              "      <td>-0.85210</td>\n",
              "      <td>-15.67150</td>\n",
              "      <td>-26.36257</td>\n",
              "      <td>5.48708</td>\n",
              "      <td>-9.13495</td>\n",
              "      <td>6.08680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>45.17809</td>\n",
              "      <td>46.34234</td>\n",
              "      <td>-40.65357</td>\n",
              "      <td>-2.47909</td>\n",
              "      <td>1.21253</td>\n",
              "      <td>-0.65302</td>\n",
              "      <td>-6.95536</td>\n",
              "      <td>-12.20040</td>\n",
              "      <td>17.02512</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.36742</td>\n",
              "      <td>-87.55285</td>\n",
              "      <td>-70.79677</td>\n",
              "      <td>76.57355</td>\n",
              "      <td>-7.71727</td>\n",
              "      <td>3.26926</td>\n",
              "      <td>-298.49845</td>\n",
              "      <td>11.49326</td>\n",
              "      <td>-89.21804</td>\n",
              "      <td>-15.09719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>39.13076</td>\n",
              "      <td>-23.01763</td>\n",
              "      <td>-36.20583</td>\n",
              "      <td>1.67519</td>\n",
              "      <td>-4.27101</td>\n",
              "      <td>13.01158</td>\n",
              "      <td>8.05718</td>\n",
              "      <td>-8.41088</td>\n",
              "      <td>6.27370</td>\n",
              "      <td>...</td>\n",
              "      <td>32.86051</td>\n",
              "      <td>-26.08461</td>\n",
              "      <td>-186.82429</td>\n",
              "      <td>113.58176</td>\n",
              "      <td>9.28727</td>\n",
              "      <td>44.60282</td>\n",
              "      <td>158.00425</td>\n",
              "      <td>-2.59543</td>\n",
              "      <td>109.19723</td>\n",
              "      <td>23.36143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>37.66498</td>\n",
              "      <td>-34.05910</td>\n",
              "      <td>-17.36060</td>\n",
              "      <td>-26.77781</td>\n",
              "      <td>-39.95119</td>\n",
              "      <td>-20.75000</td>\n",
              "      <td>-0.10231</td>\n",
              "      <td>-0.89972</td>\n",
              "      <td>-1.30205</td>\n",
              "      <td>...</td>\n",
              "      <td>11.18909</td>\n",
              "      <td>45.20614</td>\n",
              "      <td>53.83925</td>\n",
              "      <td>2.59467</td>\n",
              "      <td>-4.00958</td>\n",
              "      <td>-47.74886</td>\n",
              "      <td>-170.92864</td>\n",
              "      <td>-5.19009</td>\n",
              "      <td>8.83617</td>\n",
              "      <td>-7.16056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>26.51957</td>\n",
              "      <td>-148.15762</td>\n",
              "      <td>-13.30095</td>\n",
              "      <td>-7.25851</td>\n",
              "      <td>17.22029</td>\n",
              "      <td>-21.99439</td>\n",
              "      <td>5.51947</td>\n",
              "      <td>3.48418</td>\n",
              "      <td>2.61738</td>\n",
              "      <td>...</td>\n",
              "      <td>23.80442</td>\n",
              "      <td>251.76360</td>\n",
              "      <td>18.81642</td>\n",
              "      <td>157.09656</td>\n",
              "      <td>-27.79449</td>\n",
              "      <td>-137.72740</td>\n",
              "      <td>115.28414</td>\n",
              "      <td>23.00230</td>\n",
              "      <td>-164.02536</td>\n",
              "      <td>51.54138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>37.68491</td>\n",
              "      <td>-26.84185</td>\n",
              "      <td>-27.10566</td>\n",
              "      <td>-14.95883</td>\n",
              "      <td>-5.87200</td>\n",
              "      <td>-21.68979</td>\n",
              "      <td>4.87374</td>\n",
              "      <td>-18.01800</td>\n",
              "      <td>1.52141</td>\n",
              "      <td>...</td>\n",
              "      <td>-67.57637</td>\n",
              "      <td>234.27192</td>\n",
              "      <td>-72.34557</td>\n",
              "      <td>-362.25101</td>\n",
              "      <td>-25.55019</td>\n",
              "      <td>-89.08971</td>\n",
              "      <td>-891.58937</td>\n",
              "      <td>14.11648</td>\n",
              "      <td>-1030.99180</td>\n",
              "      <td>99.28967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>39.11695</td>\n",
              "      <td>-8.29767</td>\n",
              "      <td>-51.37966</td>\n",
              "      <td>-4.42668</td>\n",
              "      <td>-30.06506</td>\n",
              "      <td>-11.95916</td>\n",
              "      <td>-0.85322</td>\n",
              "      <td>-8.86179</td>\n",
              "      <td>11.36680</td>\n",
              "      <td>...</td>\n",
              "      <td>42.22923</td>\n",
              "      <td>478.26580</td>\n",
              "      <td>-10.33823</td>\n",
              "      <td>-103.76858</td>\n",
              "      <td>39.19511</td>\n",
              "      <td>-98.76636</td>\n",
              "      <td>-122.81061</td>\n",
              "      <td>-2.14942</td>\n",
              "      <td>-211.48202</td>\n",
              "      <td>-12.81569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>35.05129</td>\n",
              "      <td>-67.97714</td>\n",
              "      <td>-14.20239</td>\n",
              "      <td>-6.68696</td>\n",
              "      <td>-0.61230</td>\n",
              "      <td>-18.70341</td>\n",
              "      <td>-1.31928</td>\n",
              "      <td>-9.46370</td>\n",
              "      <td>5.53492</td>\n",
              "      <td>...</td>\n",
              "      <td>10.25585</td>\n",
              "      <td>94.90539</td>\n",
              "      <td>15.95689</td>\n",
              "      <td>-98.15732</td>\n",
              "      <td>-9.64859</td>\n",
              "      <td>-93.52834</td>\n",
              "      <td>-95.82981</td>\n",
              "      <td>20.73063</td>\n",
              "      <td>-562.07671</td>\n",
              "      <td>43.44696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>33.63129</td>\n",
              "      <td>-96.14912</td>\n",
              "      <td>-89.38216</td>\n",
              "      <td>-12.11699</td>\n",
              "      <td>13.77252</td>\n",
              "      <td>-6.69377</td>\n",
              "      <td>-33.36843</td>\n",
              "      <td>-24.81437</td>\n",
              "      <td>21.22757</td>\n",
              "      <td>...</td>\n",
              "      <td>49.93249</td>\n",
              "      <td>-14.47489</td>\n",
              "      <td>40.70590</td>\n",
              "      <td>58.63692</td>\n",
              "      <td>8.81522</td>\n",
              "      <td>27.28474</td>\n",
              "      <td>5.78046</td>\n",
              "      <td>3.44539</td>\n",
              "      <td>259.10825</td>\n",
              "      <td>10.28525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>41.38639</td>\n",
              "      <td>-20.78665</td>\n",
              "      <td>51.80155</td>\n",
              "      <td>17.21415</td>\n",
              "      <td>-36.44189</td>\n",
              "      <td>-11.53169</td>\n",
              "      <td>11.75252</td>\n",
              "      <td>-7.62428</td>\n",
              "      <td>-3.65488</td>\n",
              "      <td>...</td>\n",
              "      <td>50.37614</td>\n",
              "      <td>-40.48205</td>\n",
              "      <td>48.07805</td>\n",
              "      <td>-7.62399</td>\n",
              "      <td>6.51934</td>\n",
              "      <td>-30.46090</td>\n",
              "      <td>-53.87264</td>\n",
              "      <td>4.44627</td>\n",
              "      <td>58.16913</td>\n",
              "      <td>-0.02409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>37.45034</td>\n",
              "      <td>11.42615</td>\n",
              "      <td>56.28982</td>\n",
              "      <td>19.58426</td>\n",
              "      <td>-16.43530</td>\n",
              "      <td>2.22457</td>\n",
              "      <td>1.02668</td>\n",
              "      <td>-7.34736</td>\n",
              "      <td>-0.01184</td>\n",
              "      <td>...</td>\n",
              "      <td>-22.46207</td>\n",
              "      <td>-25.77228</td>\n",
              "      <td>-322.42841</td>\n",
              "      <td>-146.57408</td>\n",
              "      <td>13.61588</td>\n",
              "      <td>92.22918</td>\n",
              "      <td>-439.80259</td>\n",
              "      <td>25.73235</td>\n",
              "      <td>157.22967</td>\n",
              "      <td>38.70617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>39.71092</td>\n",
              "      <td>-4.92800</td>\n",
              "      <td>12.88590</td>\n",
              "      <td>-11.87773</td>\n",
              "      <td>2.48031</td>\n",
              "      <td>-16.11028</td>\n",
              "      <td>-16.40421</td>\n",
              "      <td>-8.29657</td>\n",
              "      <td>9.86817</td>\n",
              "      <td>...</td>\n",
              "      <td>11.92816</td>\n",
              "      <td>-73.72412</td>\n",
              "      <td>16.19039</td>\n",
              "      <td>9.79606</td>\n",
              "      <td>9.71693</td>\n",
              "      <td>-9.90907</td>\n",
              "      <td>-20.65851</td>\n",
              "      <td>2.34002</td>\n",
              "      <td>-31.57015</td>\n",
              "      <td>1.58400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20 rows × 91 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-695d2b2e-c986-4a39-83c5-fa65f8184433')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-695d2b2e-c986-4a39-83c5-fa65f8184433 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-695d2b2e-c986-4a39-83c5-fa65f8184433');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncjxI4WdzGrA"
      },
      "source": [
        "### Part (a) -- 7%\n",
        "\n",
        "The data set description text asks us to respect the below train/test split to\n",
        "avoid the \"producer effect\". That is, we want to make sure that no song from a single artist\n",
        "ends up in both the training and test set.\n",
        "\n",
        "Explain why it would be problematic to have\n",
        "some songs from an artist in the training set, and other songs from the same artist in the\n",
        "test set. (Hint: Remember that we want our test accuracy to predict how well the model\n",
        "will perform in practice on a song it hasn't learned about.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NiYlxpFzGrB"
      },
      "source": [
        "df_train = df[:463715]\n",
        "df_test = df[463715:]\n",
        "\n",
        "# convert to numpy\n",
        "train_xs = df_train[x_labels].to_numpy()\n",
        "train_ts = df_train[t_label].to_numpy()\n",
        "test_xs = df_test[x_labels].to_numpy()\n",
        "test_ts = df_test[t_label].to_numpy()\n",
        "\n",
        "# Write your explanation here\n",
        "\n",
        "# Songs from the same artist might have the same features due to the artist style.\n",
        "# In order to test our model predictions for general data, test set must include data that wasn't in the train set, otherwise,\n",
        "# we might have an overfit due to the producer effect and it will seem like good results on the test because the model overfitted to similar data.\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYSzd4XUzGrB"
      },
      "source": [
        "### Part (b) -- 7%\n",
        "\n",
        "It can be beneficial to **normalize** the columns, so that each column (feature)\n",
        "has the *same* mean and standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPuWLksJzGrB"
      },
      "source": [
        "feature_means = df_train.mean()[1:].to_numpy() # the [1:] removes the mean of the \"year\" field\n",
        "feature_stds  = df_train.std()[1:].to_numpy()\n",
        "\n",
        "train_norm_xs = (train_xs - feature_means) / feature_stds\n",
        "test_norm_xs = (test_xs - feature_means) / feature_stds"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4zmZk6ezGrC"
      },
      "source": [
        "Notice how in our code, we normalized the test set using the *training data means and standard deviations*.\n",
        "This is *not* a bug.\n",
        "\n",
        "Explain why it would be improper to compute and use test set means\n",
        "and standard deviations. (Hint: Remember what we want to use the test accuracy to measure.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxZy6brwzGrC"
      },
      "source": [
        "# Write your explanation here\n",
        "\n",
        "# We will use our test to measure the model accuracy on new data (which might not be in a set/ batch) and will test it predictions according to the\n",
        "# learned parameters during the training.\n",
        "# during inference (predictions) we will use the mean and standard deviation of the train so in order for the test\n",
        "# to represent the model accuracy during inference it shoukd use the same parameters.\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4GqL5J_zGrC"
      },
      "source": [
        "### Part (c) -- 7%\n",
        "\n",
        "Finally, we'll move some of the data in our training set into a validation set.\n",
        "\n",
        "Explain why we should limit how many times we use the test set, and that we should use the validation\n",
        "set during the model building process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsXv1U3gzGrC"
      },
      "source": [
        "# shuffle the training set\n",
        "reindex = np.random.permutation(len(train_xs))\n",
        "train_xs = train_xs[reindex]\n",
        "train_norm_xs = train_norm_xs[reindex]\n",
        "train_ts = train_ts[reindex]\n",
        "\n",
        "# use the first 50000 elements of `train_xs` as the validation set\n",
        "train_xs, val_xs           = train_xs[50000:], train_xs[:50000]\n",
        "train_norm_xs, val_norm_xs = train_norm_xs[50000:], train_norm_xs[:50000]\n",
        "train_ts, val_ts           = train_ts[50000:], train_ts[:50000]\n",
        "\n",
        "# Write your explanation here\n",
        "\n",
        "# in order for the test set to represent how well the model will perform on new data' we should be sure that we test it with a new data which wasn't a part\n",
        "# of the training considerations, hence, the test set should be used only once at the end of the process to verify the model accuracy.\n",
        "# due to the need of hyper parameters tunung and feature engineering during the model training process in order to get the best model,\n",
        "# we are splitting our train set to train and validation.\n",
        "# The validation set will be used as a test set for determining the hyper parameters and test set will be used for testing our final trained model when hyper parameters and\n",
        "# features are final\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy4lt445zGrD"
      },
      "source": [
        "## Part 2. Classification (79%)\n",
        "\n",
        "We will first build a *classification* model to perform decade classification.\n",
        "These helper functions are written for you. All other code that you write in this section should be vectorized whenever possible (i.e., avoid unnecessary loops)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6BA_s-kzGrD"
      },
      "source": [
        "def sigmoid(z):\n",
        "  return 1 / (1 + np.exp(-z))\n",
        "    \n",
        "def cross_entropy(t, y):\n",
        "  return -t * np.log(y + np.finfo(float).eps) - (1 - t) * np.log(1 - y + np.finfo(float).eps)\n",
        "\n",
        "def cost(y, t):\n",
        "  return np.mean(cross_entropy(t, y))\n",
        "\n",
        "def get_accuracy(y, t):\n",
        "  acc = 0\n",
        "  N = 0\n",
        "  for i in range(len(y)):\n",
        "    N += 1\n",
        "    if (y[i] >= 0.5 and t[i] == 1) or (y[i] < 0.5 and t[i] == 0):\n",
        "      acc += 1\n",
        "  return acc / N"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8ZIfooBzGrD"
      },
      "source": [
        "### Part (a) -- 7%\n",
        "\n",
        "Write a function `pred` that computes the prediction `y` based on logistic regression, i.e., a single layer with weights `w` and bias `b`. The output is given by: \n",
        "\\begin{equation}\n",
        "y = \\sigma({\\bf w}^T {\\bf x} + b),\n",
        "\\end{equation}\n",
        "where the value of $y$ is an estimate of the probability that the song is released in the current century, namely ${\\rm year} =1$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naY5mT4_zGrD"
      },
      "source": [
        "def pred(w, b, X):\n",
        "  \"\"\"\n",
        "  Returns the prediction `y` of the target based on the weights `w` and scalar bias `b`.\n",
        "\n",
        "  Preconditions: np.shape(w) == (90,)\n",
        "                 type(b) == float\n",
        "                 np.shape(X) = (N, 90) for some N\n",
        "\n",
        "  >>> pred(np.zeros(90), 1, np.ones([2, 90]))\n",
        "  array([0.73105858, 0.73105858]) # It's okay if your output differs in the last decimals\n",
        "  \"\"\"\n",
        "  # Your code goes here \n",
        "\n",
        "  return sigmoid(np.dot(X, w) + b)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxNdmSd3zGrE"
      },
      "source": [
        "### Part (b) -- 7%\n",
        "\n",
        "Write a function `derivative_cost` that computes and returns the gradients \n",
        "$\\frac{\\partial\\mathcal{L}}{\\partial {\\bf w}}$ and\n",
        "$\\frac{\\partial\\mathcal{L}}{\\partial b}$. Here, `X` is the input, `y` is the prediction, and `t` is the true label.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P80bu7qmzGrE"
      },
      "source": [
        "def derivative_cost(X, y, t):\n",
        "  \"\"\"\n",
        "  Returns a tuple containing the gradients dLdw and dLdb.\n",
        "\n",
        "  Precondition: np.shape(X) == (N, 90) for some N\n",
        "                np.shape(y) == (N,)\n",
        "                np.shape(t) == (N,)\n",
        "\n",
        "  Postcondition: np.shape(dLdw) = (90,)\n",
        "           type(dLdb) = float\n",
        "  \"\"\"\n",
        "  # Your code goes here\n",
        "  dldt = -(t - t**2)*np.log(y + np.finfo(float).eps) + (t - t**2)*np.log(1 + + np.finfo(float).eps - y)\n",
        "  dLdw = np.dot(X.T, dldt) / X.shape[0]\n",
        "  dLdb = np.mean(dldt)\n",
        "  return (dLdw, dLdb)\n"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okPRGM3BjKe2"
      },
      "source": [
        "# **Explenation on Gradients**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHfmPVdsg0eX"
      },
      "source": [
        "**Add here an explaination on how the gradients are computed**:\n",
        "\n",
        "Write your explanation here. Use Latex to write mathematical expressions. [Here is a brief tutorial on latex for notebooks.](https://www.math.ubc.ca/~pwalls/math-python/jupyter/latex/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhQXAKd4zGrE"
      },
      "source": [
        "### Part (c) -- 7%\n",
        "\n",
        "We can check that our derivative is implemented correctly using the finite difference rule. In 1D, the\n",
        "finite difference rule tells us that for small $h$, we should have\n",
        "\n",
        "$$\\frac{f(x+h) - f(x)}{h} \\approx f'(x)$$\n",
        "\n",
        "Show that $\\frac{\\partial\\mathcal{L}}{\\partial b}$  is implement correctly\n",
        "by comparing the result from `derivative_cost` with the empirical cost derivative computed using the above numerical approximation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpRTD-fozGrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b3b743c-1b64-4b9f-9970-eab0c8d1ab52"
      },
      "source": [
        "# Your code goes here\n",
        "\n",
        "h = 1e-09\n",
        "\n",
        "y = np.zeros(2,)\n",
        "X = np.ones([2, 90])\n",
        "w = np.zeros(90)\n",
        "b = 1\n",
        "t = pred(w, b, X)\n",
        "t_b_plus = pred(w, b + h, X)\n",
        "\n",
        "cost_t = cost(y, t)\n",
        "cost_t_b_plus = cost(y, t_b_plus)\n",
        "\n",
        "r1 = (cost_t_b_plus - cost_t) / h\n",
        "r2 = derivative_cost(X, y, t)[1]\n",
        "print(\"The analytical results is -\", r1)\n",
        "print(\"The algorithm results is - \", r2)\n",
        "\n"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The analytical results is - 7.086615738671753\n",
            "The algorithm results is -  7.086612373920213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTiplTPhzGrF"
      },
      "source": [
        "### Part (d) -- 7%\n",
        "\n",
        "Show that $\\frac{\\partial\\mathcal{L}}{\\partial {\\bf w}}$  is implement correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVTsHgnPzGrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2ee4ab0-5e23-4352-bc6c-0270d9d1410d"
      },
      "source": [
        "# Your code goes here. You might find this below code helpful: but it's\n",
        "# up to you to figure out how/why, and how to modify the code\n",
        "\n",
        "h = 1e-10\n",
        "y = np.ones(2,)\n",
        "X = np.ones([2, 90]) + np.random.randn(2, 90) * 100\n",
        "w1 = np.ones((90,)) / 1000 #Deviding by 1000 in order to make w1 values small\n",
        "b = 0\n",
        "\n",
        "t1 = pred(w1, b, X)\n",
        "t1_w1_plus = pred(w1 + h, b, X)\n",
        "\n",
        "cost_t1 = cost(y, t1)\n",
        "cost_t1_w1_plus = cost(y, t1_w1_plus)\n",
        "\n",
        "r1 = (cost_t1_w1_plus - cost_t1) / h\n",
        "r2 = np.sum(derivative_cost(X, y, t1)[0])\n",
        "print(\"The analytical results is -\", r1)\n",
        "print(\"The algorithm results is - \", r2)\n",
        "print(\"Gradient difference for w1 (analytical-algorithm): \", r1-r2)\n",
        "print(\"\\n\", '='*200, \"\\n\")\n",
        "\n",
        "# #We can also see for each w:\n",
        "# w2 = np.random.randn(90,) / 100\n",
        "# cost_t2_w2 = np.zeros((90,))\n",
        "# cost_t2_w2_plus = np.zeros((90,))\n",
        "\n",
        "# for i in range(0, len(w2)):\n",
        "#   w2_zeros = np.zeros(90,)\n",
        "#   w2_zeros[i] = w2[i]\n",
        "#   X2 = np.zeros([2,90])\n",
        "#   X2[:,i] = X[:,i]\n",
        "#   t2 = pred(w2_zeros, b, X2)\n",
        "#   t_w2_plus = pred(w2_zeros + h, b, X2)\n",
        "#   cost_t2_w2[i] = cost(y, t2)\n",
        "#   cost_t2_w2_plus[i] = cost(y, t_w2_plus)\n",
        "  \n",
        "\n",
        "# t3 = pred(w2, b, X)\n",
        "\n",
        "# r3 = (cost_t2_w2_plus - cost_t2_w2) / h\n",
        "# r4 = derivative_cost(X, y, t3)[0]\n",
        "# print(\"The analytical results is -\", r3)\n",
        "# print(\"The algorithm results is - \", r4)\n",
        "# print(\"Gradient difference for w2 (analytical-algorithm): \", r3-r4)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The analytical results is - -3268.2820005902613\n",
            "The algorithm results is -  -3268.2820369794667\n",
            "Gradient difference for w1 (analytical-algorithm):  3.638920543380664e-05\n",
            "\n",
            " ======================================================================================================================================================================================================== \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgBTPF_2zGrG"
      },
      "source": [
        "### Part (e) -- 7%\n",
        "\n",
        "Now that you have a gradient function that works, we can actually run gradient descent. \n",
        "Complete the following code that will run stochastic: gradient descent training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW4DEuuPzGrG"
      },
      "source": [
        "def run_gradient_descent(train_norm_xs, train_ts, val_norm_xs, val_ts, w0, b0, mu=0.1, batch_size=100, max_iters=100):\n",
        "  \"\"\"Return the values of (w, b) after running gradient descent for max_iters.\n",
        "  We use:\n",
        "    - train_norm_xs and train_ts as the training set\n",
        "    - val_norm_xs and val_ts as the test set\n",
        "    - mu as the learning rate\n",
        "    - (w0, b0) as the initial values of (w, b)\n",
        "\n",
        "  Precondition: np.shape(w0) == (90,)\n",
        "                type(b0) == float\n",
        " \n",
        "  Postcondition: np.shape(w) == (90,)\n",
        "                 type(b) == float\n",
        "  \"\"\"\n",
        "  w = w0\n",
        "  b = b0\n",
        "  iter = 0\n",
        "  history = {}\n",
        "  val_cost_history = []\n",
        "  val_acc_history = []\n",
        "\n",
        "  while iter < max_iters:\n",
        "    # shuffle the training set (there is code above for how to do this)\n",
        "    reindex = np.random.permutation(len(train_norm_xs))\n",
        "    train_norm_xs = train_norm_xs[reindex]\n",
        "    train_ts = train_ts[reindex]\n",
        "\n",
        "    for i in range(0, len(train_norm_xs), batch_size): # iterate over each minibatch\n",
        "      # minibatch that we are working with:\n",
        "      X = train_norm_xs[i:(i + batch_size)]\n",
        "      t = train_ts[i:(i + batch_size), 0]\n",
        "\n",
        "      # since len(train_norm_xs) does not divide batch_size evenly, we will skip over\n",
        "      # the \"last\" minibatch\n",
        "      if np.shape(X)[0] != batch_size:\n",
        "        continue\n",
        "\n",
        "      # compute the prediction\n",
        "      prediction = pred(w, b, X)\n",
        "\n",
        "      # update w and b\n",
        "      dLdw, dLdb = derivative_cost(X, t, prediction)\n",
        "      w -= dLdw*mu\n",
        "      b -= dLdb*mu\n",
        "\n",
        "      # increment the iteration count\n",
        "    iter += 1\n",
        "      # compute and print the *validation* loss and accuracy\n",
        "    if (iter % 10 == 0):\n",
        "      val_cost = 0\n",
        "      val_acc = 0\n",
        "      count = 0\n",
        "      for i in range(0, len(val_norm_xs), batch_size): # iterate over each minibatch\n",
        "        # minibatch that we are working with:\n",
        "        X = val_norm_xs[i:(i + batch_size)]\n",
        "        t = val_ts[i:(i + batch_size), 0]\n",
        "\n",
        "        val_prediction = pred(w, b, X)\n",
        "        val_cost += cost(t, val_prediction)\n",
        "        val_acc += get_accuracy(t, val_prediction)\n",
        "        count += 1\n",
        "\n",
        "      val_cost /= count\n",
        "      val_acc /= count\n",
        "      print(\"Iter %d. [Val Acc %.0f%%, Loss %f]\" % (\n",
        "              iter, val_acc * 100, val_cost))\n",
        "      val_cost_history.append(val_cost)\n",
        "      val_acc_history.append(val_acc)\n",
        "\n",
        "      if iter >= max_iters:\n",
        "        break\n",
        "\n",
        "      # Think what parameters you should return for further use\n",
        "  history[\"val_cost\"] = val_cost_history\n",
        "  history[\"val_acc\"] = val_acc_history\n",
        "  return history, (w, b)\n",
        "\n"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MqzT0jGzGrH"
      },
      "source": [
        "### Part (f) -- 7%\n",
        "\n",
        "Call `run_gradient_descent` with the weights and biases all initialized to zero.\n",
        "Show that if the learning rate $\\mu$ is too small, then convergence is slow.\n",
        "Also, show that if $\\mu$ is too large, then the optimization algorirthm does not converge. The demonstration should be made using plots showing these effects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE32Iqo6zGrH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17992ce9-6fd1-4c76-cda2-8f11f0b97c96"
      },
      "source": [
        "w0 = np.random.randn(90)\n",
        "b0 = np.random.randn(1)[0]\n",
        "\n",
        "# Write your code here\n",
        "print(\"Small mu: \")\n",
        "small_mu_history, parameters_small = run_gradient_descent(train_norm_xs, train_ts, val_norm_xs, val_ts, w0, b0, mu=5e-2, batch_size=100, max_iters=100)\n",
        "print(\"\\n\\n\", '='*200, \"\\n\\nLarge mu: \")\n",
        "large_mu_history, parameters_large = run_gradient_descent(train_norm_xs, train_ts, val_norm_xs, val_ts, w0, b0, mu=3e+5, batch_size=100, max_iters=100)\n"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Small mu: \n",
            "Iter 10. [Val Acc 2%, Loss 9.518329]\n",
            "Iter 20. [Val Acc 3%, Loss 9.497378]\n",
            "Iter 30. [Val Acc 4%, Loss 9.489970]\n",
            "Iter 40. [Val Acc 6%, Loss 9.479998]\n",
            "Iter 50. [Val Acc 6%, Loss 9.466772]\n",
            "Iter 60. [Val Acc 7%, Loss 9.468726]\n",
            "Iter 70. [Val Acc 8%, Loss 9.468629]\n",
            "Iter 80. [Val Acc 9%, Loss 9.460367]\n",
            "Iter 90. [Val Acc 10%, Loss 9.463793]\n",
            "Iter 100. [Val Acc 10%, Loss 9.473047]\n",
            "\n",
            "\n",
            " ======================================================================================================================================================================================================== \n",
            "\n",
            "Large mu: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 10. [Val Acc 53%, Loss 16.936192]\n",
            "Iter 20. [Val Acc 56%, Loss 15.887322]\n",
            "Iter 30. [Val Acc 56%, Loss 15.903902]\n",
            "Iter 40. [Val Acc 56%, Loss 15.903902]\n",
            "Iter 50. [Val Acc 56%, Loss 15.903902]\n",
            "Iter 60. [Val Acc 56%, Loss 15.903902]\n",
            "Iter 70. [Val Acc 56%, Loss 15.903902]\n",
            "Iter 80. [Val Acc 56%, Loss 15.903902]\n",
            "Iter 90. [Val Acc 56%, Loss 15.903902]\n",
            "Iter 100. [Val Acc 56%, Loss 15.903902]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "def plot_acc_loss(acc_history, loss_history, iteration_resolution):\n",
        "  \"\"\"Plot the values of validation accuracy and loss from model train history lists.\n",
        "  We use:\n",
        "    - acc_historys as the accuracy history list\n",
        "    - loss_history as the loss history list\n",
        "    - iteration_resolution as the values iterations resolution\n",
        "\n",
        "  Precondition: type(acc_history) == list(flaot)\n",
        " \n",
        "  Postcondition: type(loss_history) == list(flaot)\n",
        "  \"\"\"\n",
        "  iterations = range(iteration_resolution, len(acc_history)*iteration_resolution + iteration_resolution, 10)\n",
        "  \n",
        "  plt.figure(figsize=[20,4])\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(iterations[:], acc_history[:], \"b-\")\n",
        "  plt.xlabel(\"iteration\", fontsize=14)\n",
        "  plt.ylabel(\"Validation Accuracy\", rotation=90, fontsize=14)\n",
        "  ax1 = plt.gca()\n",
        "  ax1.set(ylim=(max(acc_history) - 0.2, max(acc_history) + 0.2))\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure(figsize=[20,4])\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(iterations[:], loss_history[:], \"r-\")\n",
        "  plt.xlabel(\"iteration\", fontsize=14)\n",
        "  plt.ylabel(\"Validation Loss\", rotation=90, fontsize=14)\n",
        "  ax2 = plt.gca()\n",
        "  ax2.set(ylim=(min(loss_history) - 0.5, max(loss_history) +0.5))\n",
        "  plt.grid()\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "3BGW2webqpY9"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_acc_loss(small_mu_history[\"val_acc\"], small_mu_history[\"val_cost\"], 10)"
      ],
      "metadata": {
        "id": "4Ng2E7nTvtvw",
        "outputId": "4da69cc9-8d28-4b38-c0b5-b83ef026a7da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 552
        }
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_acc_loss(large_mu_history[\"val_acc\"], large_mu_history[\"val_cost\"], 10)\n"
      ],
      "metadata": {
        "id": "NvXTevDK18rY",
        "outputId": "6d085a24-30d9-4676-8543-739ba6fade6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        }
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S44GmUZ12o-g"
      },
      "source": [
        "**Explain and discuss your results here:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ5HlDFAzGrH"
      },
      "source": [
        "### Part (g) -- 7%\n",
        "\n",
        "Find the optimial value of ${\\bf w}$ and $b$ using your code. Explain how you chose\n",
        "the learning rate $\\mu$ and the batch size. Show plots demostrating good and bad behaviours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dFOFSwgzGrI"
      },
      "source": [
        "w0 = np.random.randn(90)\n",
        "b0 = np.random.randn(1)[0]\n",
        "\n",
        "# Write your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkZt7_932zX2"
      },
      "source": [
        "**Explain and discuss your results here:**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KrQqSj2zGrI"
      },
      "source": [
        "### Part (h) -- 15%\n",
        "\n",
        "Using the values of `w` and `b` from part (g), compute your training accuracy, validation accuracy,\n",
        "and test accuracy. Are there any differences between those three values? If so, why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuKw2mLozGrI"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "train_acc = ...\n",
        "val_acc = ...\n",
        "test_acc = ...\n",
        "\n",
        "print('train_acc = ', train_acc, ' val_acc = ', val_acc, ' test_acc = ', test_acc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXZa1u6920M3"
      },
      "source": [
        "**Explain and discuss your results here:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4eP2Yh1zGrI"
      },
      "source": [
        "### Part (i) -- 15%\n",
        "\n",
        "Writing a classifier like this is instructive, and helps you understand what happens when\n",
        "we train a model. However, in practice, we rarely write model building and training code\n",
        "from scratch. Instead, we typically use one of the well-tested libraries available in a package.\n",
        "\n",
        "Use `sklearn.linear_model.LogisticRegression` to build a linear classifier, and make predictions about the test set. Start by reading the\n",
        "[API documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
        "\n",
        "Compute the training, validation and test accuracy of this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24LCfAa1zGrJ"
      },
      "source": [
        "import sklearn.linear_model\n",
        "\n",
        "model = ...\n",
        "\n",
        "train_acc = ...\n",
        "val_acc = ...\n",
        "test_acc = ...\n",
        "\n",
        "print('train_acc = ', train_acc, ' val_acc = ', val_acc, ' test_acc = ', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRqucdV923tG"
      },
      "source": [
        "**This parts helps by checking if the code worked.**\n",
        "**Check if you get similar results, if not repair your code**\n"
      ]
    }
  ]
}