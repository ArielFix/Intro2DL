{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArielFix/Intro2DL/blob/OnGoingAssignment1/Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bhfIKbQzGq2"
      },
      "source": [
        "# Assignment 1. Music Century Classification\n",
        "\n",
        "**Assignment Responsible**: Natalie Lang.\n",
        "\n",
        "In this assignment, we will build models to predict which\n",
        "**century** a piece of music was released.  We will be using the \"YearPredictionMSD Data Set\"\n",
        "based on the Million Song Dataset. The data is available to download from the UCI \n",
        "Machine Learning Repository. Here are some links about the data:\n",
        "\n",
        "- https://archive.ics.uci.edu/ml/datasets/yearpredictionmsd\n",
        "- http://millionsongdataset.com/pages/tasks-demos/#yearrecognition\n",
        "\n",
        "Note that you are note allowed to import additional packages **(especially not PyTorch)**. One of the objectives is to understand how the training procedure actually operates, before working with PyTorch's autograd engine which does it all for us.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47oq1vy5PUIV"
      },
      "source": [
        "## Question 1. Data (21%)\n",
        "\n",
        "Start by setting up a Google Colab notebook in which to do your work.\n",
        "Since you are working with a partner, you might find this link helpful:\n",
        "\n",
        "- https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb\n",
        "\n",
        "The recommended way to work together is pair coding, where you and your partner are sitting together and writing code together. \n",
        "\n",
        "To process and read the data, we use the popular `pandas` package for data analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aFWpuNSzGq9"
      },
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7UWL6mFzGq-"
      },
      "source": [
        "Now that your notebook is set up, we can load the data into the notebook. The code below provides\n",
        "two ways of loading the data: directly from the internet, or through mounting Google Drive.\n",
        "The first method is easier but slower, and the second method is a bit involved at first, but\n",
        "can save you time later on. You will need to mount Google Drive for later assignments, so we recommend\n",
        "figuring how to do that now.\n",
        "\n",
        "Here are some resources to help you get started:\n",
        "\n",
        "- http.://colab.research.google.com/notebooks/io.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY6PrfV4zGq_",
        "outputId": "f859bb38-d42c-4da9-e008-feb2a59c147b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "load_from_drive = True\n",
        "\n",
        "if not load_from_drive:\n",
        "  csv_path = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip\"\n",
        "else:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  csv_path = '/content/gdrive/My Drive/MSc/Courses/Into to Deep Learnig/Assignments/YearPredictionMSD.txt.zip' # TODO - UPDATE ME WITH THE TRUE PATH!\n",
        "\n",
        "t_label = [\"year\"]\n",
        "x_labels = [\"var%d\" % i for i in range(1, 91)]\n",
        "df = pandas.read_csv(csv_path, names=t_label + x_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgB83beNzGq_"
      },
      "source": [
        "Now that the data is loaded to your Colab notebook, you should be able to display the Pandas\n",
        "DataFrame `df` as a table:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5bBEnj3zGq_",
        "outputId": "3289fad9-ada2-43ca-ca8a-ada566dcdeb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        year      var1      var2      var3      var4      var5      var6  \\\n",
              "0       2001  49.94357  21.47114  73.07750   8.74861 -17.40628 -13.09905   \n",
              "1       2001  48.73215  18.42930  70.32679  12.94636 -10.32437 -24.83777   \n",
              "2       2001  50.95714  31.85602  55.81851  13.41693  -6.57898 -18.54940   \n",
              "3       2001  48.24750  -1.89837  36.29772   2.58776   0.97170 -26.21683   \n",
              "4       2001  50.97020  42.20998  67.09964   8.46791 -15.85279 -16.81409   \n",
              "...      ...       ...       ...       ...       ...       ...       ...   \n",
              "515340  2006  51.28467  45.88068  22.19582  -5.53319  -3.61835 -16.36914   \n",
              "515341  2006  49.87870  37.93125  18.65987  -3.63581 -27.75665 -18.52988   \n",
              "515342  2006  45.12852  12.65758 -38.72018   8.80882 -29.29985  -2.28706   \n",
              "515343  2006  44.16614  32.38368  -3.34971  -2.49165 -19.59278 -18.67098   \n",
              "515344  2005  51.85726  59.11655  26.39436  -5.46030 -20.69012 -19.95528   \n",
              "\n",
              "            var7      var8      var9  ...     var81      var82      var83  \\\n",
              "0      -25.01202 -12.23257   7.83089  ...  13.01620  -54.40548   58.99367   \n",
              "1        8.76630  -0.92019  18.76548  ...   5.66812  -19.68073   33.04964   \n",
              "2       -3.27872  -2.35035  16.07017  ...   3.03800   26.05866  -50.92779   \n",
              "3        5.05097 -10.34124   3.55005  ...  34.57337 -171.70734  -16.96705   \n",
              "4      -12.48207  -9.37636  12.63699  ...   9.92661  -55.95724   64.92712   \n",
              "...          ...       ...       ...  ...       ...        ...        ...   \n",
              "515340   2.12652   5.18160  -8.66890  ...   4.81440   -3.75991  -30.92584   \n",
              "515341   7.76108   3.56109  -2.50351  ...  32.38589  -32.75535  -61.05473   \n",
              "515342 -18.40424 -22.28726  -4.52429  ... -18.73598  -71.15954 -123.98443   \n",
              "515343   8.78428   4.02039 -12.01230  ...  67.16763  282.77624   -4.63677   \n",
              "515344  -6.72771   2.29590  10.31018  ... -11.50511  -69.18291   60.58456   \n",
              "\n",
              "            var84     var85     var86      var87     var88      var89  \\\n",
              "0        15.37344   1.11144 -23.08793   68.40795  -1.82223  -27.46348   \n",
              "1        42.87836  -9.90378 -32.22788   70.49388  12.04941   58.43453   \n",
              "2        10.93792  -0.07568  43.20130 -115.00698  -0.05859   39.67068   \n",
              "3       -46.67617 -12.51516  82.58061  -72.08993   9.90558  199.62971   \n",
              "4       -17.72522  -1.49237  -7.50035   51.76631   7.88713   55.66926   \n",
              "...           ...       ...       ...        ...       ...        ...   \n",
              "515340   26.33968  -5.03390  21.86037 -142.29410   3.42901  -41.14721   \n",
              "515341   56.65182  15.29965  95.88193  -10.63242  12.96552   92.11633   \n",
              "515342  121.26989  10.89629  34.62409 -248.61020  -6.07171   53.96319   \n",
              "515343  144.00125  21.62652 -29.72432   71.47198  20.32240   14.83107   \n",
              "515344   28.64599  -4.39620 -64.56491  -45.61012  -5.51512   32.35602   \n",
              "\n",
              "           var90  \n",
              "0        2.26327  \n",
              "1       26.92061  \n",
              "2       -0.66345  \n",
              "3       18.85382  \n",
              "4       28.74903  \n",
              "...          ...  \n",
              "515340 -15.46052  \n",
              "515341  10.88815  \n",
              "515342  -8.09364  \n",
              "515343  39.74909  \n",
              "515344  12.17352  \n",
              "\n",
              "[515345 rows x 91 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ec64d16-d735-46d1-99f1-a1a95548f313\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>var1</th>\n",
              "      <th>var2</th>\n",
              "      <th>var3</th>\n",
              "      <th>var4</th>\n",
              "      <th>var5</th>\n",
              "      <th>var6</th>\n",
              "      <th>var7</th>\n",
              "      <th>var8</th>\n",
              "      <th>var9</th>\n",
              "      <th>...</th>\n",
              "      <th>var81</th>\n",
              "      <th>var82</th>\n",
              "      <th>var83</th>\n",
              "      <th>var84</th>\n",
              "      <th>var85</th>\n",
              "      <th>var86</th>\n",
              "      <th>var87</th>\n",
              "      <th>var88</th>\n",
              "      <th>var89</th>\n",
              "      <th>var90</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>49.94357</td>\n",
              "      <td>21.47114</td>\n",
              "      <td>73.07750</td>\n",
              "      <td>8.74861</td>\n",
              "      <td>-17.40628</td>\n",
              "      <td>-13.09905</td>\n",
              "      <td>-25.01202</td>\n",
              "      <td>-12.23257</td>\n",
              "      <td>7.83089</td>\n",
              "      <td>...</td>\n",
              "      <td>13.01620</td>\n",
              "      <td>-54.40548</td>\n",
              "      <td>58.99367</td>\n",
              "      <td>15.37344</td>\n",
              "      <td>1.11144</td>\n",
              "      <td>-23.08793</td>\n",
              "      <td>68.40795</td>\n",
              "      <td>-1.82223</td>\n",
              "      <td>-27.46348</td>\n",
              "      <td>2.26327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.73215</td>\n",
              "      <td>18.42930</td>\n",
              "      <td>70.32679</td>\n",
              "      <td>12.94636</td>\n",
              "      <td>-10.32437</td>\n",
              "      <td>-24.83777</td>\n",
              "      <td>8.76630</td>\n",
              "      <td>-0.92019</td>\n",
              "      <td>18.76548</td>\n",
              "      <td>...</td>\n",
              "      <td>5.66812</td>\n",
              "      <td>-19.68073</td>\n",
              "      <td>33.04964</td>\n",
              "      <td>42.87836</td>\n",
              "      <td>-9.90378</td>\n",
              "      <td>-32.22788</td>\n",
              "      <td>70.49388</td>\n",
              "      <td>12.04941</td>\n",
              "      <td>58.43453</td>\n",
              "      <td>26.92061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.95714</td>\n",
              "      <td>31.85602</td>\n",
              "      <td>55.81851</td>\n",
              "      <td>13.41693</td>\n",
              "      <td>-6.57898</td>\n",
              "      <td>-18.54940</td>\n",
              "      <td>-3.27872</td>\n",
              "      <td>-2.35035</td>\n",
              "      <td>16.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>3.03800</td>\n",
              "      <td>26.05866</td>\n",
              "      <td>-50.92779</td>\n",
              "      <td>10.93792</td>\n",
              "      <td>-0.07568</td>\n",
              "      <td>43.20130</td>\n",
              "      <td>-115.00698</td>\n",
              "      <td>-0.05859</td>\n",
              "      <td>39.67068</td>\n",
              "      <td>-0.66345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.24750</td>\n",
              "      <td>-1.89837</td>\n",
              "      <td>36.29772</td>\n",
              "      <td>2.58776</td>\n",
              "      <td>0.97170</td>\n",
              "      <td>-26.21683</td>\n",
              "      <td>5.05097</td>\n",
              "      <td>-10.34124</td>\n",
              "      <td>3.55005</td>\n",
              "      <td>...</td>\n",
              "      <td>34.57337</td>\n",
              "      <td>-171.70734</td>\n",
              "      <td>-16.96705</td>\n",
              "      <td>-46.67617</td>\n",
              "      <td>-12.51516</td>\n",
              "      <td>82.58061</td>\n",
              "      <td>-72.08993</td>\n",
              "      <td>9.90558</td>\n",
              "      <td>199.62971</td>\n",
              "      <td>18.85382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.97020</td>\n",
              "      <td>42.20998</td>\n",
              "      <td>67.09964</td>\n",
              "      <td>8.46791</td>\n",
              "      <td>-15.85279</td>\n",
              "      <td>-16.81409</td>\n",
              "      <td>-12.48207</td>\n",
              "      <td>-9.37636</td>\n",
              "      <td>12.63699</td>\n",
              "      <td>...</td>\n",
              "      <td>9.92661</td>\n",
              "      <td>-55.95724</td>\n",
              "      <td>64.92712</td>\n",
              "      <td>-17.72522</td>\n",
              "      <td>-1.49237</td>\n",
              "      <td>-7.50035</td>\n",
              "      <td>51.76631</td>\n",
              "      <td>7.88713</td>\n",
              "      <td>55.66926</td>\n",
              "      <td>28.74903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515340</th>\n",
              "      <td>2006</td>\n",
              "      <td>51.28467</td>\n",
              "      <td>45.88068</td>\n",
              "      <td>22.19582</td>\n",
              "      <td>-5.53319</td>\n",
              "      <td>-3.61835</td>\n",
              "      <td>-16.36914</td>\n",
              "      <td>2.12652</td>\n",
              "      <td>5.18160</td>\n",
              "      <td>-8.66890</td>\n",
              "      <td>...</td>\n",
              "      <td>4.81440</td>\n",
              "      <td>-3.75991</td>\n",
              "      <td>-30.92584</td>\n",
              "      <td>26.33968</td>\n",
              "      <td>-5.03390</td>\n",
              "      <td>21.86037</td>\n",
              "      <td>-142.29410</td>\n",
              "      <td>3.42901</td>\n",
              "      <td>-41.14721</td>\n",
              "      <td>-15.46052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515341</th>\n",
              "      <td>2006</td>\n",
              "      <td>49.87870</td>\n",
              "      <td>37.93125</td>\n",
              "      <td>18.65987</td>\n",
              "      <td>-3.63581</td>\n",
              "      <td>-27.75665</td>\n",
              "      <td>-18.52988</td>\n",
              "      <td>7.76108</td>\n",
              "      <td>3.56109</td>\n",
              "      <td>-2.50351</td>\n",
              "      <td>...</td>\n",
              "      <td>32.38589</td>\n",
              "      <td>-32.75535</td>\n",
              "      <td>-61.05473</td>\n",
              "      <td>56.65182</td>\n",
              "      <td>15.29965</td>\n",
              "      <td>95.88193</td>\n",
              "      <td>-10.63242</td>\n",
              "      <td>12.96552</td>\n",
              "      <td>92.11633</td>\n",
              "      <td>10.88815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515342</th>\n",
              "      <td>2006</td>\n",
              "      <td>45.12852</td>\n",
              "      <td>12.65758</td>\n",
              "      <td>-38.72018</td>\n",
              "      <td>8.80882</td>\n",
              "      <td>-29.29985</td>\n",
              "      <td>-2.28706</td>\n",
              "      <td>-18.40424</td>\n",
              "      <td>-22.28726</td>\n",
              "      <td>-4.52429</td>\n",
              "      <td>...</td>\n",
              "      <td>-18.73598</td>\n",
              "      <td>-71.15954</td>\n",
              "      <td>-123.98443</td>\n",
              "      <td>121.26989</td>\n",
              "      <td>10.89629</td>\n",
              "      <td>34.62409</td>\n",
              "      <td>-248.61020</td>\n",
              "      <td>-6.07171</td>\n",
              "      <td>53.96319</td>\n",
              "      <td>-8.09364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515343</th>\n",
              "      <td>2006</td>\n",
              "      <td>44.16614</td>\n",
              "      <td>32.38368</td>\n",
              "      <td>-3.34971</td>\n",
              "      <td>-2.49165</td>\n",
              "      <td>-19.59278</td>\n",
              "      <td>-18.67098</td>\n",
              "      <td>8.78428</td>\n",
              "      <td>4.02039</td>\n",
              "      <td>-12.01230</td>\n",
              "      <td>...</td>\n",
              "      <td>67.16763</td>\n",
              "      <td>282.77624</td>\n",
              "      <td>-4.63677</td>\n",
              "      <td>144.00125</td>\n",
              "      <td>21.62652</td>\n",
              "      <td>-29.72432</td>\n",
              "      <td>71.47198</td>\n",
              "      <td>20.32240</td>\n",
              "      <td>14.83107</td>\n",
              "      <td>39.74909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515344</th>\n",
              "      <td>2005</td>\n",
              "      <td>51.85726</td>\n",
              "      <td>59.11655</td>\n",
              "      <td>26.39436</td>\n",
              "      <td>-5.46030</td>\n",
              "      <td>-20.69012</td>\n",
              "      <td>-19.95528</td>\n",
              "      <td>-6.72771</td>\n",
              "      <td>2.29590</td>\n",
              "      <td>10.31018</td>\n",
              "      <td>...</td>\n",
              "      <td>-11.50511</td>\n",
              "      <td>-69.18291</td>\n",
              "      <td>60.58456</td>\n",
              "      <td>28.64599</td>\n",
              "      <td>-4.39620</td>\n",
              "      <td>-64.56491</td>\n",
              "      <td>-45.61012</td>\n",
              "      <td>-5.51512</td>\n",
              "      <td>32.35602</td>\n",
              "      <td>12.17352</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>515345 rows × 91 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ec64d16-d735-46d1-99f1-a1a95548f313')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6ec64d16-d735-46d1-99f1-a1a95548f313 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6ec64d16-d735-46d1-99f1-a1a95548f313');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaLuAMH_zGrA"
      },
      "source": [
        "To set up our data for classification, we'll use the \"year\" field to represent\n",
        "whether a song was released in the 20-th century. In our case `df[\"year\"]` will be 1 if\n",
        "the year was released after 2000, and 0 otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZdGlNgdzGrA"
      },
      "source": [
        "df[\"year\"] = df[\"year\"].map(lambda x: int(x > 2000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xugy7FZ8eoAd",
        "outputId": "9422226d-0186-43b4-cac9-d484531dd08a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        }
      },
      "source": [
        "df.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    year      var1       var2      var3      var4      var5      var6  \\\n",
              "0      1  49.94357   21.47114  73.07750   8.74861 -17.40628 -13.09905   \n",
              "1      1  48.73215   18.42930  70.32679  12.94636 -10.32437 -24.83777   \n",
              "2      1  50.95714   31.85602  55.81851  13.41693  -6.57898 -18.54940   \n",
              "3      1  48.24750   -1.89837  36.29772   2.58776   0.97170 -26.21683   \n",
              "4      1  50.97020   42.20998  67.09964   8.46791 -15.85279 -16.81409   \n",
              "5      1  50.54767    0.31568  92.35066  22.38696 -25.51870 -19.04928   \n",
              "6      1  50.57546   33.17843  50.53517  11.55217 -27.24764  -8.78206   \n",
              "7      1  48.26892    8.97526  75.23158  24.04945 -16.02105 -14.09491   \n",
              "8      1  49.75468   33.99581  56.73846   2.89581  -2.92429 -26.44413   \n",
              "9      1  45.17809   46.34234 -40.65357  -2.47909   1.21253  -0.65302   \n",
              "10     1  39.13076  -23.01763 -36.20583   1.67519  -4.27101  13.01158   \n",
              "11     1  37.66498  -34.05910 -17.36060 -26.77781 -39.95119 -20.75000   \n",
              "12     1  26.51957 -148.15762 -13.30095  -7.25851  17.22029 -21.99439   \n",
              "13     1  37.68491  -26.84185 -27.10566 -14.95883  -5.87200 -21.68979   \n",
              "14     0  39.11695   -8.29767 -51.37966  -4.42668 -30.06506 -11.95916   \n",
              "15     1  35.05129  -67.97714 -14.20239  -6.68696  -0.61230 -18.70341   \n",
              "16     1  33.63129  -96.14912 -89.38216 -12.11699  13.77252  -6.69377   \n",
              "17     0  41.38639  -20.78665  51.80155  17.21415 -36.44189 -11.53169   \n",
              "18     0  37.45034   11.42615  56.28982  19.58426 -16.43530   2.22457   \n",
              "19     0  39.71092   -4.92800  12.88590 -11.87773   2.48031 -16.11028   \n",
              "\n",
              "        var7      var8      var9  ...     var81      var82      var83  \\\n",
              "0  -25.01202 -12.23257   7.83089  ...  13.01620  -54.40548   58.99367   \n",
              "1    8.76630  -0.92019  18.76548  ...   5.66812  -19.68073   33.04964   \n",
              "2   -3.27872  -2.35035  16.07017  ...   3.03800   26.05866  -50.92779   \n",
              "3    5.05097 -10.34124   3.55005  ...  34.57337 -171.70734  -16.96705   \n",
              "4  -12.48207  -9.37636  12.63699  ...   9.92661  -55.95724   64.92712   \n",
              "5   20.67345  -5.19943   3.63566  ...   6.59753  -50.69577   26.02574   \n",
              "6  -12.04282  -9.53930  28.61811  ...  11.63681   25.44182  134.62382   \n",
              "7    8.11871  -1.87566   7.46701  ...  18.03989  -58.46192  -65.56438   \n",
              "8    1.71392  -0.55644  22.08594  ...  18.70812    5.20391  -27.75192   \n",
              "9   -6.95536 -12.20040  17.02512  ...  -4.36742  -87.55285  -70.79677   \n",
              "10   8.05718  -8.41088   6.27370  ...  32.86051  -26.08461 -186.82429   \n",
              "11  -0.10231  -0.89972  -1.30205  ...  11.18909   45.20614   53.83925   \n",
              "12   5.51947   3.48418   2.61738  ...  23.80442  251.76360   18.81642   \n",
              "13   4.87374 -18.01800   1.52141  ... -67.57637  234.27192  -72.34557   \n",
              "14  -0.85322  -8.86179  11.36680  ...  42.22923  478.26580  -10.33823   \n",
              "15  -1.31928  -9.46370   5.53492  ...  10.25585   94.90539   15.95689   \n",
              "16 -33.36843 -24.81437  21.22757  ...  49.93249  -14.47489   40.70590   \n",
              "17  11.75252  -7.62428  -3.65488  ...  50.37614  -40.48205   48.07805   \n",
              "18   1.02668  -7.34736  -0.01184  ... -22.46207  -25.77228 -322.42841   \n",
              "19 -16.40421  -8.29657   9.86817  ...  11.92816  -73.72412   16.19039   \n",
              "\n",
              "        var84     var85      var86      var87     var88       var89     var90  \n",
              "0    15.37344   1.11144  -23.08793   68.40795  -1.82223   -27.46348   2.26327  \n",
              "1    42.87836  -9.90378  -32.22788   70.49388  12.04941    58.43453  26.92061  \n",
              "2    10.93792  -0.07568   43.20130 -115.00698  -0.05859    39.67068  -0.66345  \n",
              "3   -46.67617 -12.51516   82.58061  -72.08993   9.90558   199.62971  18.85382  \n",
              "4   -17.72522  -1.49237   -7.50035   51.76631   7.88713    55.66926  28.74903  \n",
              "5    18.94430  -0.33730    6.09352   35.18381   5.00283   -11.02257   0.02263  \n",
              "6    21.51982   8.17570   35.46251   11.57736   4.50056    -4.62739   1.40192  \n",
              "7    46.99856  -4.09602   56.37650  -18.29975  -0.30633     3.98364  -3.72556  \n",
              "8    17.22100  -0.85210  -15.67150  -26.36257   5.48708    -9.13495   6.08680  \n",
              "9    76.57355  -7.71727    3.26926 -298.49845  11.49326   -89.21804 -15.09719  \n",
              "10  113.58176   9.28727   44.60282  158.00425  -2.59543   109.19723  23.36143  \n",
              "11    2.59467  -4.00958  -47.74886 -170.92864  -5.19009     8.83617  -7.16056  \n",
              "12  157.09656 -27.79449 -137.72740  115.28414  23.00230  -164.02536  51.54138  \n",
              "13 -362.25101 -25.55019  -89.08971 -891.58937  14.11648 -1030.99180  99.28967  \n",
              "14 -103.76858  39.19511  -98.76636 -122.81061  -2.14942  -211.48202 -12.81569  \n",
              "15  -98.15732  -9.64859  -93.52834  -95.82981  20.73063  -562.07671  43.44696  \n",
              "16   58.63692   8.81522   27.28474    5.78046   3.44539   259.10825  10.28525  \n",
              "17   -7.62399   6.51934  -30.46090  -53.87264   4.44627    58.16913  -0.02409  \n",
              "18 -146.57408  13.61588   92.22918 -439.80259  25.73235   157.22967  38.70617  \n",
              "19    9.79606   9.71693   -9.90907  -20.65851   2.34002   -31.57015   1.58400  \n",
              "\n",
              "[20 rows x 91 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-695d2b2e-c986-4a39-83c5-fa65f8184433\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>var1</th>\n",
              "      <th>var2</th>\n",
              "      <th>var3</th>\n",
              "      <th>var4</th>\n",
              "      <th>var5</th>\n",
              "      <th>var6</th>\n",
              "      <th>var7</th>\n",
              "      <th>var8</th>\n",
              "      <th>var9</th>\n",
              "      <th>...</th>\n",
              "      <th>var81</th>\n",
              "      <th>var82</th>\n",
              "      <th>var83</th>\n",
              "      <th>var84</th>\n",
              "      <th>var85</th>\n",
              "      <th>var86</th>\n",
              "      <th>var87</th>\n",
              "      <th>var88</th>\n",
              "      <th>var89</th>\n",
              "      <th>var90</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>49.94357</td>\n",
              "      <td>21.47114</td>\n",
              "      <td>73.07750</td>\n",
              "      <td>8.74861</td>\n",
              "      <td>-17.40628</td>\n",
              "      <td>-13.09905</td>\n",
              "      <td>-25.01202</td>\n",
              "      <td>-12.23257</td>\n",
              "      <td>7.83089</td>\n",
              "      <td>...</td>\n",
              "      <td>13.01620</td>\n",
              "      <td>-54.40548</td>\n",
              "      <td>58.99367</td>\n",
              "      <td>15.37344</td>\n",
              "      <td>1.11144</td>\n",
              "      <td>-23.08793</td>\n",
              "      <td>68.40795</td>\n",
              "      <td>-1.82223</td>\n",
              "      <td>-27.46348</td>\n",
              "      <td>2.26327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>48.73215</td>\n",
              "      <td>18.42930</td>\n",
              "      <td>70.32679</td>\n",
              "      <td>12.94636</td>\n",
              "      <td>-10.32437</td>\n",
              "      <td>-24.83777</td>\n",
              "      <td>8.76630</td>\n",
              "      <td>-0.92019</td>\n",
              "      <td>18.76548</td>\n",
              "      <td>...</td>\n",
              "      <td>5.66812</td>\n",
              "      <td>-19.68073</td>\n",
              "      <td>33.04964</td>\n",
              "      <td>42.87836</td>\n",
              "      <td>-9.90378</td>\n",
              "      <td>-32.22788</td>\n",
              "      <td>70.49388</td>\n",
              "      <td>12.04941</td>\n",
              "      <td>58.43453</td>\n",
              "      <td>26.92061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>50.95714</td>\n",
              "      <td>31.85602</td>\n",
              "      <td>55.81851</td>\n",
              "      <td>13.41693</td>\n",
              "      <td>-6.57898</td>\n",
              "      <td>-18.54940</td>\n",
              "      <td>-3.27872</td>\n",
              "      <td>-2.35035</td>\n",
              "      <td>16.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>3.03800</td>\n",
              "      <td>26.05866</td>\n",
              "      <td>-50.92779</td>\n",
              "      <td>10.93792</td>\n",
              "      <td>-0.07568</td>\n",
              "      <td>43.20130</td>\n",
              "      <td>-115.00698</td>\n",
              "      <td>-0.05859</td>\n",
              "      <td>39.67068</td>\n",
              "      <td>-0.66345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>48.24750</td>\n",
              "      <td>-1.89837</td>\n",
              "      <td>36.29772</td>\n",
              "      <td>2.58776</td>\n",
              "      <td>0.97170</td>\n",
              "      <td>-26.21683</td>\n",
              "      <td>5.05097</td>\n",
              "      <td>-10.34124</td>\n",
              "      <td>3.55005</td>\n",
              "      <td>...</td>\n",
              "      <td>34.57337</td>\n",
              "      <td>-171.70734</td>\n",
              "      <td>-16.96705</td>\n",
              "      <td>-46.67617</td>\n",
              "      <td>-12.51516</td>\n",
              "      <td>82.58061</td>\n",
              "      <td>-72.08993</td>\n",
              "      <td>9.90558</td>\n",
              "      <td>199.62971</td>\n",
              "      <td>18.85382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50.97020</td>\n",
              "      <td>42.20998</td>\n",
              "      <td>67.09964</td>\n",
              "      <td>8.46791</td>\n",
              "      <td>-15.85279</td>\n",
              "      <td>-16.81409</td>\n",
              "      <td>-12.48207</td>\n",
              "      <td>-9.37636</td>\n",
              "      <td>12.63699</td>\n",
              "      <td>...</td>\n",
              "      <td>9.92661</td>\n",
              "      <td>-55.95724</td>\n",
              "      <td>64.92712</td>\n",
              "      <td>-17.72522</td>\n",
              "      <td>-1.49237</td>\n",
              "      <td>-7.50035</td>\n",
              "      <td>51.76631</td>\n",
              "      <td>7.88713</td>\n",
              "      <td>55.66926</td>\n",
              "      <td>28.74903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>50.54767</td>\n",
              "      <td>0.31568</td>\n",
              "      <td>92.35066</td>\n",
              "      <td>22.38696</td>\n",
              "      <td>-25.51870</td>\n",
              "      <td>-19.04928</td>\n",
              "      <td>20.67345</td>\n",
              "      <td>-5.19943</td>\n",
              "      <td>3.63566</td>\n",
              "      <td>...</td>\n",
              "      <td>6.59753</td>\n",
              "      <td>-50.69577</td>\n",
              "      <td>26.02574</td>\n",
              "      <td>18.94430</td>\n",
              "      <td>-0.33730</td>\n",
              "      <td>6.09352</td>\n",
              "      <td>35.18381</td>\n",
              "      <td>5.00283</td>\n",
              "      <td>-11.02257</td>\n",
              "      <td>0.02263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>50.57546</td>\n",
              "      <td>33.17843</td>\n",
              "      <td>50.53517</td>\n",
              "      <td>11.55217</td>\n",
              "      <td>-27.24764</td>\n",
              "      <td>-8.78206</td>\n",
              "      <td>-12.04282</td>\n",
              "      <td>-9.53930</td>\n",
              "      <td>28.61811</td>\n",
              "      <td>...</td>\n",
              "      <td>11.63681</td>\n",
              "      <td>25.44182</td>\n",
              "      <td>134.62382</td>\n",
              "      <td>21.51982</td>\n",
              "      <td>8.17570</td>\n",
              "      <td>35.46251</td>\n",
              "      <td>11.57736</td>\n",
              "      <td>4.50056</td>\n",
              "      <td>-4.62739</td>\n",
              "      <td>1.40192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>48.26892</td>\n",
              "      <td>8.97526</td>\n",
              "      <td>75.23158</td>\n",
              "      <td>24.04945</td>\n",
              "      <td>-16.02105</td>\n",
              "      <td>-14.09491</td>\n",
              "      <td>8.11871</td>\n",
              "      <td>-1.87566</td>\n",
              "      <td>7.46701</td>\n",
              "      <td>...</td>\n",
              "      <td>18.03989</td>\n",
              "      <td>-58.46192</td>\n",
              "      <td>-65.56438</td>\n",
              "      <td>46.99856</td>\n",
              "      <td>-4.09602</td>\n",
              "      <td>56.37650</td>\n",
              "      <td>-18.29975</td>\n",
              "      <td>-0.30633</td>\n",
              "      <td>3.98364</td>\n",
              "      <td>-3.72556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>49.75468</td>\n",
              "      <td>33.99581</td>\n",
              "      <td>56.73846</td>\n",
              "      <td>2.89581</td>\n",
              "      <td>-2.92429</td>\n",
              "      <td>-26.44413</td>\n",
              "      <td>1.71392</td>\n",
              "      <td>-0.55644</td>\n",
              "      <td>22.08594</td>\n",
              "      <td>...</td>\n",
              "      <td>18.70812</td>\n",
              "      <td>5.20391</td>\n",
              "      <td>-27.75192</td>\n",
              "      <td>17.22100</td>\n",
              "      <td>-0.85210</td>\n",
              "      <td>-15.67150</td>\n",
              "      <td>-26.36257</td>\n",
              "      <td>5.48708</td>\n",
              "      <td>-9.13495</td>\n",
              "      <td>6.08680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>45.17809</td>\n",
              "      <td>46.34234</td>\n",
              "      <td>-40.65357</td>\n",
              "      <td>-2.47909</td>\n",
              "      <td>1.21253</td>\n",
              "      <td>-0.65302</td>\n",
              "      <td>-6.95536</td>\n",
              "      <td>-12.20040</td>\n",
              "      <td>17.02512</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.36742</td>\n",
              "      <td>-87.55285</td>\n",
              "      <td>-70.79677</td>\n",
              "      <td>76.57355</td>\n",
              "      <td>-7.71727</td>\n",
              "      <td>3.26926</td>\n",
              "      <td>-298.49845</td>\n",
              "      <td>11.49326</td>\n",
              "      <td>-89.21804</td>\n",
              "      <td>-15.09719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>39.13076</td>\n",
              "      <td>-23.01763</td>\n",
              "      <td>-36.20583</td>\n",
              "      <td>1.67519</td>\n",
              "      <td>-4.27101</td>\n",
              "      <td>13.01158</td>\n",
              "      <td>8.05718</td>\n",
              "      <td>-8.41088</td>\n",
              "      <td>6.27370</td>\n",
              "      <td>...</td>\n",
              "      <td>32.86051</td>\n",
              "      <td>-26.08461</td>\n",
              "      <td>-186.82429</td>\n",
              "      <td>113.58176</td>\n",
              "      <td>9.28727</td>\n",
              "      <td>44.60282</td>\n",
              "      <td>158.00425</td>\n",
              "      <td>-2.59543</td>\n",
              "      <td>109.19723</td>\n",
              "      <td>23.36143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>37.66498</td>\n",
              "      <td>-34.05910</td>\n",
              "      <td>-17.36060</td>\n",
              "      <td>-26.77781</td>\n",
              "      <td>-39.95119</td>\n",
              "      <td>-20.75000</td>\n",
              "      <td>-0.10231</td>\n",
              "      <td>-0.89972</td>\n",
              "      <td>-1.30205</td>\n",
              "      <td>...</td>\n",
              "      <td>11.18909</td>\n",
              "      <td>45.20614</td>\n",
              "      <td>53.83925</td>\n",
              "      <td>2.59467</td>\n",
              "      <td>-4.00958</td>\n",
              "      <td>-47.74886</td>\n",
              "      <td>-170.92864</td>\n",
              "      <td>-5.19009</td>\n",
              "      <td>8.83617</td>\n",
              "      <td>-7.16056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>26.51957</td>\n",
              "      <td>-148.15762</td>\n",
              "      <td>-13.30095</td>\n",
              "      <td>-7.25851</td>\n",
              "      <td>17.22029</td>\n",
              "      <td>-21.99439</td>\n",
              "      <td>5.51947</td>\n",
              "      <td>3.48418</td>\n",
              "      <td>2.61738</td>\n",
              "      <td>...</td>\n",
              "      <td>23.80442</td>\n",
              "      <td>251.76360</td>\n",
              "      <td>18.81642</td>\n",
              "      <td>157.09656</td>\n",
              "      <td>-27.79449</td>\n",
              "      <td>-137.72740</td>\n",
              "      <td>115.28414</td>\n",
              "      <td>23.00230</td>\n",
              "      <td>-164.02536</td>\n",
              "      <td>51.54138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>37.68491</td>\n",
              "      <td>-26.84185</td>\n",
              "      <td>-27.10566</td>\n",
              "      <td>-14.95883</td>\n",
              "      <td>-5.87200</td>\n",
              "      <td>-21.68979</td>\n",
              "      <td>4.87374</td>\n",
              "      <td>-18.01800</td>\n",
              "      <td>1.52141</td>\n",
              "      <td>...</td>\n",
              "      <td>-67.57637</td>\n",
              "      <td>234.27192</td>\n",
              "      <td>-72.34557</td>\n",
              "      <td>-362.25101</td>\n",
              "      <td>-25.55019</td>\n",
              "      <td>-89.08971</td>\n",
              "      <td>-891.58937</td>\n",
              "      <td>14.11648</td>\n",
              "      <td>-1030.99180</td>\n",
              "      <td>99.28967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>39.11695</td>\n",
              "      <td>-8.29767</td>\n",
              "      <td>-51.37966</td>\n",
              "      <td>-4.42668</td>\n",
              "      <td>-30.06506</td>\n",
              "      <td>-11.95916</td>\n",
              "      <td>-0.85322</td>\n",
              "      <td>-8.86179</td>\n",
              "      <td>11.36680</td>\n",
              "      <td>...</td>\n",
              "      <td>42.22923</td>\n",
              "      <td>478.26580</td>\n",
              "      <td>-10.33823</td>\n",
              "      <td>-103.76858</td>\n",
              "      <td>39.19511</td>\n",
              "      <td>-98.76636</td>\n",
              "      <td>-122.81061</td>\n",
              "      <td>-2.14942</td>\n",
              "      <td>-211.48202</td>\n",
              "      <td>-12.81569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>35.05129</td>\n",
              "      <td>-67.97714</td>\n",
              "      <td>-14.20239</td>\n",
              "      <td>-6.68696</td>\n",
              "      <td>-0.61230</td>\n",
              "      <td>-18.70341</td>\n",
              "      <td>-1.31928</td>\n",
              "      <td>-9.46370</td>\n",
              "      <td>5.53492</td>\n",
              "      <td>...</td>\n",
              "      <td>10.25585</td>\n",
              "      <td>94.90539</td>\n",
              "      <td>15.95689</td>\n",
              "      <td>-98.15732</td>\n",
              "      <td>-9.64859</td>\n",
              "      <td>-93.52834</td>\n",
              "      <td>-95.82981</td>\n",
              "      <td>20.73063</td>\n",
              "      <td>-562.07671</td>\n",
              "      <td>43.44696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>33.63129</td>\n",
              "      <td>-96.14912</td>\n",
              "      <td>-89.38216</td>\n",
              "      <td>-12.11699</td>\n",
              "      <td>13.77252</td>\n",
              "      <td>-6.69377</td>\n",
              "      <td>-33.36843</td>\n",
              "      <td>-24.81437</td>\n",
              "      <td>21.22757</td>\n",
              "      <td>...</td>\n",
              "      <td>49.93249</td>\n",
              "      <td>-14.47489</td>\n",
              "      <td>40.70590</td>\n",
              "      <td>58.63692</td>\n",
              "      <td>8.81522</td>\n",
              "      <td>27.28474</td>\n",
              "      <td>5.78046</td>\n",
              "      <td>3.44539</td>\n",
              "      <td>259.10825</td>\n",
              "      <td>10.28525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>41.38639</td>\n",
              "      <td>-20.78665</td>\n",
              "      <td>51.80155</td>\n",
              "      <td>17.21415</td>\n",
              "      <td>-36.44189</td>\n",
              "      <td>-11.53169</td>\n",
              "      <td>11.75252</td>\n",
              "      <td>-7.62428</td>\n",
              "      <td>-3.65488</td>\n",
              "      <td>...</td>\n",
              "      <td>50.37614</td>\n",
              "      <td>-40.48205</td>\n",
              "      <td>48.07805</td>\n",
              "      <td>-7.62399</td>\n",
              "      <td>6.51934</td>\n",
              "      <td>-30.46090</td>\n",
              "      <td>-53.87264</td>\n",
              "      <td>4.44627</td>\n",
              "      <td>58.16913</td>\n",
              "      <td>-0.02409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>37.45034</td>\n",
              "      <td>11.42615</td>\n",
              "      <td>56.28982</td>\n",
              "      <td>19.58426</td>\n",
              "      <td>-16.43530</td>\n",
              "      <td>2.22457</td>\n",
              "      <td>1.02668</td>\n",
              "      <td>-7.34736</td>\n",
              "      <td>-0.01184</td>\n",
              "      <td>...</td>\n",
              "      <td>-22.46207</td>\n",
              "      <td>-25.77228</td>\n",
              "      <td>-322.42841</td>\n",
              "      <td>-146.57408</td>\n",
              "      <td>13.61588</td>\n",
              "      <td>92.22918</td>\n",
              "      <td>-439.80259</td>\n",
              "      <td>25.73235</td>\n",
              "      <td>157.22967</td>\n",
              "      <td>38.70617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>39.71092</td>\n",
              "      <td>-4.92800</td>\n",
              "      <td>12.88590</td>\n",
              "      <td>-11.87773</td>\n",
              "      <td>2.48031</td>\n",
              "      <td>-16.11028</td>\n",
              "      <td>-16.40421</td>\n",
              "      <td>-8.29657</td>\n",
              "      <td>9.86817</td>\n",
              "      <td>...</td>\n",
              "      <td>11.92816</td>\n",
              "      <td>-73.72412</td>\n",
              "      <td>16.19039</td>\n",
              "      <td>9.79606</td>\n",
              "      <td>9.71693</td>\n",
              "      <td>-9.90907</td>\n",
              "      <td>-20.65851</td>\n",
              "      <td>2.34002</td>\n",
              "      <td>-31.57015</td>\n",
              "      <td>1.58400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20 rows × 91 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-695d2b2e-c986-4a39-83c5-fa65f8184433')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-695d2b2e-c986-4a39-83c5-fa65f8184433 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-695d2b2e-c986-4a39-83c5-fa65f8184433');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncjxI4WdzGrA"
      },
      "source": [
        "### Part (a) -- 7%\n",
        "\n",
        "The data set description text asks us to respect the below train/test split to\n",
        "avoid the \"producer effect\". That is, we want to make sure that no song from a single artist\n",
        "ends up in both the training and test set.\n",
        "\n",
        "Explain why it would be problematic to have\n",
        "some songs from an artist in the training set, and other songs from the same artist in the\n",
        "test set. (Hint: Remember that we want our test accuracy to predict how well the model\n",
        "will perform in practice on a song it hasn't learned about.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NiYlxpFzGrB"
      },
      "source": [
        "df_train = df[:463715]\n",
        "df_test = df[463715:]\n",
        "\n",
        "# convert to numpy\n",
        "train_xs = df_train[x_labels].to_numpy()\n",
        "train_ts = df_train[t_label].to_numpy()\n",
        "test_xs = df_test[x_labels].to_numpy()\n",
        "test_ts = df_test[t_label].to_numpy()\n",
        "\n",
        "# Write your explanation here\n",
        "\n",
        "# Songs from the same artist might have the same features due to the artist style.\n",
        "# In order to test our model predictions for general data, test set must include data that wasn't in the train set, otherwise,\n",
        "# we might have an overfit due to the producer effect and it will seem like good results on the test because the model overfitted to similar data.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYSzd4XUzGrB"
      },
      "source": [
        "### Part (b) -- 7%\n",
        "\n",
        "It can be beneficial to **normalize** the columns, so that each column (feature)\n",
        "has the *same* mean and standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPuWLksJzGrB"
      },
      "source": [
        "feature_means = df_train.mean()[1:].to_numpy() # the [1:] removes the mean of the \"year\" field\n",
        "feature_stds  = df_train.std()[1:].to_numpy()\n",
        "\n",
        "train_norm_xs = (train_xs - feature_means) / feature_stds\n",
        "test_norm_xs = (test_xs - feature_means) / feature_stds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4zmZk6ezGrC"
      },
      "source": [
        "Notice how in our code, we normalized the test set using the *training data means and standard deviations*.\n",
        "This is *not* a bug.\n",
        "\n",
        "Explain why it would be improper to compute and use test set means\n",
        "and standard deviations. (Hint: Remember what we want to use the test accuracy to measure.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxZy6brwzGrC"
      },
      "source": [
        "# Write your explanation here\n",
        "\n",
        "# We will use our test to measure the model accuracy on new data (which might not be in a set/ batch) and will test it predictions according to the\n",
        "# learned parameters during the training.\n",
        "# during inference (predictions) we will use the mean and standard deviation of the train so in order for the test\n",
        "# to represent the model accuracy during inference it shoukd use the same parameters.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4GqL5J_zGrC"
      },
      "source": [
        "### Part (c) -- 7%\n",
        "\n",
        "Finally, we'll move some of the data in our training set into a validation set.\n",
        "\n",
        "Explain why we should limit how many times we use the test set, and that we should use the validation\n",
        "set during the model building process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsXv1U3gzGrC"
      },
      "source": [
        "# shuffle the training set\n",
        "reindex = np.random.permutation(len(train_xs))\n",
        "train_xs = train_xs[reindex]\n",
        "train_norm_xs = train_norm_xs[reindex]\n",
        "train_ts = train_ts[reindex]\n",
        "\n",
        "# use the first 50000 elements of `train_xs` as the validation set\n",
        "train_xs, val_xs           = train_xs[50000:], train_xs[:50000]\n",
        "train_norm_xs, val_norm_xs = train_norm_xs[50000:], train_norm_xs[:50000]\n",
        "train_ts, val_ts           = train_ts[50000:], train_ts[:50000]\n",
        "\n",
        "# Write your explanation here\n",
        "\n",
        "# in order for the test set to represent how well the model will perform on new data' we should be sure that we test it with a new data which wasn't a part\n",
        "# of the training considerations, hence, the test set should be used only once at the end of the process to verify the model accuracy.\n",
        "# due to the need of hyper parameters tunung and feature engineering during the model training process in order to get the best model,\n",
        "# we are splitting our train set to train and validation.\n",
        "# The validation set will be used as a test set for determining the hyper parameters and test set will be used for testing our final trained model when hyper parameters and\n",
        "# features are final\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy4lt445zGrD"
      },
      "source": [
        "## Part 2. Classification (79%)\n",
        "\n",
        "We will first build a *classification* model to perform decade classification.\n",
        "These helper functions are written for you. All other code that you write in this section should be vectorized whenever possible (i.e., avoid unnecessary loops)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6BA_s-kzGrD"
      },
      "source": [
        "def sigmoid(z):\n",
        "  return 1 / (1 + np.exp(-z))\n",
        "    \n",
        "def cross_entropy(t, y):\n",
        "  return -t * np.log(y + np.finfo(float).eps) - (1 - t) * np.log(1 - y + np.finfo(float).eps)\n",
        "\n",
        "def cost(y, t):\n",
        "  return np.mean(cross_entropy(t, y))\n",
        "\n",
        "def get_accuracy(y, t):\n",
        "  acc = 0\n",
        "  N = 0\n",
        "  for i in range(len(y)):\n",
        "    N += 1\n",
        "    if (y[i] >= 0.5 and t[i] == 1) or (y[i] < 0.5 and t[i] == 0):\n",
        "      acc += 1\n",
        "  return acc / N"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8ZIfooBzGrD"
      },
      "source": [
        "### Part (a) -- 7%\n",
        "\n",
        "Write a function `pred` that computes the prediction `y` based on logistic regression, i.e., a single layer with weights `w` and bias `b`. The output is given by: \n",
        "\\begin{equation}\n",
        "y = \\sigma({\\bf w}^T {\\bf x} + b),\n",
        "\\end{equation}\n",
        "where the value of $y$ is an estimate of the probability that the song is released in the current century, namely ${\\rm year} =1$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naY5mT4_zGrD"
      },
      "source": [
        "def pred(w, b, X):\n",
        "  \"\"\"\n",
        "  Returns the prediction `y` of the target based on the weights `w` and scalar bias `b`.\n",
        "\n",
        "  Preconditions: np.shape(w) == (90,)\n",
        "                 type(b) == float\n",
        "                 np.shape(X) = (N, 90) for some N\n",
        "\n",
        "  >>> pred(np.zeros(90), 1, np.ones([2, 90]))\n",
        "  array([0.73105858, 0.73105858]) # It's okay if your output differs in the last decimals\n",
        "  \"\"\"\n",
        "  # Your code goes here \n",
        "\n",
        "  return sigmoid(np.dot(X, w) + b)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxNdmSd3zGrE"
      },
      "source": [
        "### Part (b) -- 7%\n",
        "\n",
        "Write a function `derivative_cost` that computes and returns the gradients \n",
        "$\\frac{\\partial\\mathcal{L}}{\\partial {\\bf w}}$ and\n",
        "$\\frac{\\partial\\mathcal{L}}{\\partial b}$. Here, `X` is the input, `y` is the prediction, and `t` is the true label.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P80bu7qmzGrE"
      },
      "source": [
        "def derivative_cost(X, y, t):\n",
        "  \"\"\"\n",
        "  Returns a tuple containing the gradients dLdw and dLdb.\n",
        "\n",
        "  Precondition: np.shape(X) == (N, 90) for some N\n",
        "                np.shape(y) == (N,)\n",
        "                np.shape(t) == (N,)\n",
        "\n",
        "  Postcondition: np.shape(dLdw) = (90,)\n",
        "           type(dLdb) = float\n",
        "  \"\"\"\n",
        "  # Your code goes here\n",
        "  dldt = t*(1-y) + y*(1-t)\n",
        "  dLdw = np.dot(X.T, dldt) / X.shape[0]\n",
        "  dLdb = np.mean(dldt)\n",
        "  return (dLdw, dLdb)\n"
      ],
      "execution_count": 445,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okPRGM3BjKe2"
      },
      "source": [
        "# **Explenation on Gradients**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHfmPVdsg0eX"
      },
      "source": [
        "**Add here an explaination on how the gradients are computed**:\n",
        "\n",
        "Write your explanation here. Use Latex to write mathematical expressions. [Here is a brief tutorial on latex for notebooks.](https://www.math.ubc.ca/~pwalls/math-python/jupyter/latex/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhQXAKd4zGrE"
      },
      "source": [
        "### Part (c) -- 7%\n",
        "\n",
        "We can check that our derivative is implemented correctly using the finite difference rule. In 1D, the\n",
        "finite difference rule tells us that for small $h$, we should have\n",
        "\n",
        "$$\\frac{f(x+h) - f(x)}{h} \\approx f'(x)$$\n",
        "\n",
        "Show that $\\frac{\\partial\\mathcal{L}}{\\partial b}$  is implement correctly\n",
        "by comparing the result from `derivative_cost` with the empirical cost derivative computed using the above numerical approximation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpRTD-fozGrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7da0c120-5d00-4b4b-e49e-10c3a47dd82d"
      },
      "source": [
        "# Your code goes here\n",
        "\n",
        "h = 1e-09\n",
        "\n",
        "t = np.zeros(2,)\n",
        "X = np.ones([2, 90])\n",
        "w = np.zeros(90)\n",
        "b = 1\n",
        "y = pred(w, b, X)\n",
        "y_b_plus = pred(w, b + h, X)\n",
        "\n",
        "cost_y = cost(y, t)\n",
        "cost_y_b_plus = cost(y_b_plus, t)\n",
        "\n",
        "r1 = (cost_y_b_plus - cost_y) / h\n",
        "r2 = derivative_cost(X, y, t)[1]\n",
        "print(\"The analytical results is: \", r1)\n",
        "print(\"The algorithm results is: \", r2)\n",
        "print(\"Gradient difference for w1 (analytical-algorithm): \", r1-r2)\n"
      ],
      "execution_count": 446,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The analytical results is:  0.7310585470321485\n",
            "The algorithm results is:  0.7310585786300049\n",
            "Gradient difference for w1 (analytical-algorithm):  -3.159785644246682e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTiplTPhzGrF"
      },
      "source": [
        "### Part (d) -- 7%\n",
        "\n",
        "Show that $\\frac{\\partial\\mathcal{L}}{\\partial {\\bf w}}$  is implement correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVTsHgnPzGrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa44c2f-3375-4edf-c6fe-bdc029540e93"
      },
      "source": [
        "# Your code goes here. You might find this below code helpful: but it's\n",
        "# up to you to figure out how/why, and how to modify the code\n",
        "\n",
        "h = 1e-10\n",
        "t = np.zeros(2,)\n",
        "X1 = np.ones([2, 90]) #+ np.random.randn(2, 90)\n",
        "w1 = np.random.randn(90,) \n",
        "b = 0\n",
        "\n",
        "y1 = pred(w1, b, X1)\n",
        "y1_w1_plus = pred(w1 + h, b, X1)\n",
        "\n",
        "cost_y1 = cost(y1, t)\n",
        "cost_y1_w1_plus = cost(y1_w1_plus, t)\n",
        "\n",
        "r1 = (cost_y1_w1_plus - cost_y1) / h\n",
        "r2 = np.sum(derivative_cost(X1, y1, t)[0])\n",
        "print(\"The analytical results is: \", r1)\n",
        "print(\"The algorithm results is: \", r2)\n",
        "print(\"Gradient difference for w1 (analytical-algorithm): \", r1-r2)\n",
        "print(\"\\n\", '='*200, \"\\n\")\n",
        "\n",
        "# #We can also see for each w:\n",
        "# w2 = np.random.randn(90,) \n",
        "# cost_y2_w2 = np.zeros([90,])\n",
        "# cost_y2_w2_plus = np.zeros([90,])\n",
        "\n",
        "# for i in range(0, len(w1)):\n",
        "#   w2_zeros = np.zeros([90,])\n",
        "#   w2_zeros_plus = np.zeros([90,])\n",
        "#   X_zeros = np.zeros(np.shape(X1))\n",
        "#   X_zeros[:, i] = X1[:, i]\n",
        "#   w2_zeros[i] = w1[i]\n",
        "#   y2 = pred(w2_zeros, b, X_zeros)\n",
        "#   w2_zeros_plus[i] = w1[i] + h\n",
        "#   y2_w2_plus = pred(w2_zeros_plus, b, X_zeros)\n",
        "#   cost_y2_w2[i] = cost(y2, t)\n",
        "#   cost_y2_w2_plus[i] = cost(y2_w2_plus, t)\n",
        "  \n",
        "\n",
        "# y3 = pred(w1, b, X1)\n",
        "\n",
        "# r3 = (cost_y2_w2_plus - cost_y2_w2) / h\n",
        "# r4 = derivative_cost(X1, y3, t)[0]\n",
        "# print(\"The analytical results is:\", r3)\n",
        "# print(\"The algorithm results is: \", r4)\n",
        "# print(\"Gradient difference for w2 (analytical-algorithm): \", r3-r4)"
      ],
      "execution_count": 475,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The analytical results is:  25.116704271965773\n",
            "The algorithm results is:  25.11670129277158\n",
            "Gradient difference for w1 (analytical-algorithm):  2.9791941926760046e-06\n",
            "\n",
            " ======================================================================================================================================================================================================== \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgBTPF_2zGrG"
      },
      "source": [
        "### Part (e) -- 7%\n",
        "\n",
        "Now that you have a gradient function that works, we can actually run gradient descent. \n",
        "Complete the following code that will run stochastic: gradient descent training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW4DEuuPzGrG"
      },
      "source": [
        "def run_gradient_descent(train_norm_xs, train_ts, val_norm_xs, val_ts, w0, b0, mu=0.1, batch_size=100, max_iters=100):\n",
        "  \"\"\"Return the values of (w, b) after running gradient descent for max_iters.\n",
        "  We use:\n",
        "    - train_norm_xs and train_ts as the training set\n",
        "    - val_norm_xs and val_ts as the test set\n",
        "    - mu as the learning rate\n",
        "    - (w0, b0) as the initial values of (w, b)\n",
        "\n",
        "  Precondition: np.shape(w0) == (90,)\n",
        "                type(b0) == float\n",
        " \n",
        "  Postcondition: np.shape(w) == (90,)\n",
        "                 type(b) == float\n",
        "  \"\"\"\n",
        "  w = w0\n",
        "  b = b0\n",
        "  iter = 0\n",
        "  history = {}\n",
        "  val_cost_history = []\n",
        "  val_acc_history = []\n",
        "\n",
        "  while iter < max_iters:\n",
        "    # shuffle the training set (there is code above for how to do this)\n",
        "    reindex = np.random.permutation(len(train_norm_xs))\n",
        "    train_norm_xs = train_norm_xs[reindex]\n",
        "    train_ts = train_ts[reindex]\n",
        "\n",
        "    for i in range(0, len(train_norm_xs), batch_size): # iterate over each minibatch\n",
        "      # minibatch that we are working with:\n",
        "      X = train_norm_xs[i:(i + batch_size)]\n",
        "      t = train_ts[i:(i + batch_size), 0]\n",
        "\n",
        "      # since len(train_norm_xs) does not divide batch_size evenly, we will skip over\n",
        "      # the \"last\" minibatch\n",
        "      if np.shape(X)[0] != batch_size:\n",
        "        continue\n",
        "\n",
        "      # compute the prediction\n",
        "      prediction = pred(w, b, X)\n",
        "\n",
        "      # update w and b\n",
        "      dLdw, dLdb = derivative_cost(X, t, prediction)\n",
        "      w -= dLdw*mu\n",
        "      b -= dLdb*mu\n",
        "\n",
        "      # increment the iteration count\n",
        "    iter += 1\n",
        "      # compute and print the *validation* loss and accuracy\n",
        "    if (iter % 10 == 0):\n",
        "      val_cost = 0\n",
        "      val_acc = 0\n",
        "      count = 0\n",
        "      for i in range(0, len(val_norm_xs), batch_size): # iterate over each minibatch\n",
        "        # minibatch that we are working with:\n",
        "        X = val_norm_xs[i:(i + batch_size)]\n",
        "        t = val_ts[i:(i + batch_size), 0]\n",
        "\n",
        "        val_prediction = pred(w, b, X)\n",
        "        val_cost += cost(t, val_prediction)\n",
        "        val_acc += get_accuracy(t, val_prediction)\n",
        "        count += 1\n",
        "\n",
        "      val_cost /= count\n",
        "      val_acc /= count\n",
        "      print(\"Iter %d. [Val Acc %.0f%%, Loss %f]\" % (\n",
        "              iter, val_acc * 100, val_cost))\n",
        "      val_cost_history.append(val_cost)\n",
        "      val_acc_history.append(val_acc)\n",
        "\n",
        "      if iter >= max_iters:\n",
        "        break\n",
        "\n",
        "      # Think what parameters you should return for further use\n",
        "  history[\"val_cost\"] = val_cost_history\n",
        "  history[\"val_acc\"] = val_acc_history\n",
        "  return history, (w, b)\n",
        "\n"
      ],
      "execution_count": 330,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MqzT0jGzGrH"
      },
      "source": [
        "### Part (f) -- 7%\n",
        "\n",
        "Call `run_gradient_descent` with the weights and biases all initialized to zero.\n",
        "Show that if the learning rate $\\mu$ is too small, then convergence is slow.\n",
        "Also, show that if $\\mu$ is too large, then the optimization algorirthm does not converge. The demonstration should be made using plots showing these effects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE32Iqo6zGrH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46c4733b-2583-479f-d2b3-fb151ac8b20a"
      },
      "source": [
        "w0 = np.random.randn(90)\n",
        "b0 = np.random.randn(1)[0]\n",
        "\n",
        "# Write your code here\n",
        "print(\"Small mu: \")\n",
        "small_mu_history, parameters_small = run_gradient_descent(train_norm_xs, train_ts, val_norm_xs, val_ts, w0, b0, mu=5e-2, batch_size=100, max_iters=300)\n",
        "print(\"\\n\\n\", '='*200, \"\\n\\nLarge mu: \")\n",
        "large_mu_history, parameters_large = run_gradient_descent(train_norm_xs, train_ts, val_norm_xs, val_ts, w0, b0, mu=3e+5, batch_size=100, max_iters=300)\n"
      ],
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Small mu: \n",
            "Iter 10. [Val Acc 4%, Loss 9.575402]\n",
            "Iter 20. [Val Acc 7%, Loss 9.547942]\n",
            "Iter 30. [Val Acc 9%, Loss 9.537122]\n",
            "Iter 40. [Val Acc 11%, Loss 9.537931]\n",
            "Iter 50. [Val Acc 13%, Loss 9.525056]\n",
            "Iter 60. [Val Acc 14%, Loss 9.525491]\n",
            "Iter 70. [Val Acc 15%, Loss 9.519828]\n",
            "Iter 80. [Val Acc 16%, Loss 9.522784]\n",
            "Iter 90. [Val Acc 17%, Loss 9.515264]\n",
            "Iter 100. [Val Acc 18%, Loss 9.521146]\n",
            "Iter 110. [Val Acc 19%, Loss 9.510165]\n",
            "Iter 120. [Val Acc 20%, Loss 9.507378]\n",
            "Iter 130. [Val Acc 20%, Loss 9.510266]\n",
            "Iter 140. [Val Acc 21%, Loss 9.510017]\n",
            "Iter 150. [Val Acc 21%, Loss 9.527881]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 160. [Val Acc 22%, Loss 9.509025]\n",
            "Iter 170. [Val Acc 22%, Loss 9.515540]\n",
            "Iter 180. [Val Acc 23%, Loss 9.524418]\n",
            "Iter 190. [Val Acc 23%, Loss 9.508337]\n",
            "Iter 200. [Val Acc 24%, Loss 9.510288]\n",
            "Iter 210. [Val Acc 24%, Loss 9.512092]\n",
            "Iter 220. [Val Acc 24%, Loss 9.510959]\n",
            "Iter 230. [Val Acc 24%, Loss 9.506614]\n",
            "Iter 240. [Val Acc 25%, Loss 9.512720]\n",
            "Iter 250. [Val Acc 25%, Loss 9.509552]\n",
            "Iter 260. [Val Acc 25%, Loss 9.500246]\n",
            "Iter 270. [Val Acc 26%, Loss 9.515033]\n",
            "Iter 280. [Val Acc 26%, Loss 9.495622]\n",
            "Iter 290. [Val Acc 26%, Loss 9.512575]\n",
            "Iter 300. [Val Acc 26%, Loss 9.497798]\n",
            "\n",
            "\n",
            " ======================================================================================================================================================================================================== \n",
            "\n",
            "Large mu: \n",
            "Iter 10. [Val Acc 54%, Loss 16.458253]\n",
            "Iter 20. [Val Acc 57%, Loss 15.330808]\n",
            "Iter 30. [Val Acc 58%, Loss 15.135451]\n",
            "Iter 40. [Val Acc 56%, Loss 15.737380]\n",
            "Iter 50. [Val Acc 60%, Loss 14.428995]\n",
            "Iter 60. [Val Acc 61%, Loss 14.215617]\n",
            "Iter 70. [Val Acc 61%, Loss 14.215617]\n",
            "Iter 80. [Val Acc 61%, Loss 14.215617]\n",
            "Iter 90. [Val Acc 61%, Loss 14.215617]\n",
            "Iter 100. [Val Acc 61%, Loss 14.215617]\n",
            "Iter 110. [Val Acc 61%, Loss 14.215617]\n",
            "Iter 120. [Val Acc 61%, Loss 14.215617]\n",
            "Iter 130. [Val Acc 61%, Loss 14.215617]\n",
            "Iter 140. [Val Acc 61%, Loss 14.215617]\n",
            "Iter 150. [Val Acc 61%, Loss 14.215617]\n",
            "Iter 160. [Val Acc 61%, Loss 14.215617]\n",
            "Iter 170. [Val Acc 61%, Loss 14.215617]\n",
            "Iter 180. [Val Acc 61%, Loss 14.215617]\n",
            "Iter 190. [Val Acc 61%, Loss 14.215617]\n",
            "Iter 200. [Val Acc 61%, Loss 14.215617]\n",
            "Iter 210. [Val Acc 61%, Loss 14.215617]\n",
            "Iter 220. [Val Acc 61%, Loss 14.215617]\n",
            "Iter 230. [Val Acc 61%, Loss 14.215617]\n",
            "Iter 240. [Val Acc 61%, Loss 14.215617]\n",
            "Iter 250. [Val Acc 61%, Loss 14.215617]\n",
            "Iter 260. [Val Acc 61%, Loss 14.215617]\n",
            "Iter 270. [Val Acc 61%, Loss 14.215617]\n",
            "Iter 280. [Val Acc 61%, Loss 14.215617]\n",
            "Iter 290. [Val Acc 61%, Loss 14.215617]\n",
            "Iter 300. [Val Acc 61%, Loss 14.215617]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "def plot_acc_loss(acc_history, loss_history, iteration_resolution):\n",
        "  \"\"\"Plot the values of validation accuracy and loss from model train history lists.\n",
        "  We use:\n",
        "    - acc_historys as the accuracy history list\n",
        "    - loss_history as the loss history list\n",
        "    - iteration_resolution as the values iterations resolution\n",
        "\n",
        "  Precondition: type(acc_history) == list(flaot)\n",
        " \n",
        "  Postcondition: type(loss_history) == list(flaot)\n",
        "  \"\"\"\n",
        "  iterations = range(iteration_resolution, len(acc_history)*iteration_resolution + iteration_resolution, 10)\n",
        "  \n",
        "  plt.figure(figsize=[20,4])\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(iterations[:], acc_history[:], \"b-\")\n",
        "  plt.xlabel(\"iteration\", fontsize=14)\n",
        "  plt.ylabel(\"Validation Accuracy\", rotation=90, fontsize=14)\n",
        "  ax1 = plt.gca()\n",
        "  ax1.set(ylim=(max(acc_history) - 0.2, max(acc_history) + 0.2))\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure(figsize=[20,4])\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(iterations[:], loss_history[:], \"r-\")\n",
        "  plt.xlabel(\"iteration\", fontsize=14)\n",
        "  plt.ylabel(\"Validation Loss\", rotation=90, fontsize=14)\n",
        "  ax2 = plt.gca()\n",
        "  ax2.set(ylim=(min(loss_history) - 0.5, max(loss_history) +0.5))\n",
        "  plt.grid()\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "3BGW2webqpY9"
      },
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_acc_loss(small_mu_history[\"val_acc\"], small_mu_history[\"val_cost\"], 10)"
      ],
      "metadata": {
        "id": "4Ng2E7nTvtvw",
        "outputId": "e33555ff-9f60-47f6-dea8-14c4944c759c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        }
      },
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_acc_loss(large_mu_history[\"val_acc\"], large_mu_history[\"val_cost\"], 10)\n"
      ],
      "metadata": {
        "id": "NvXTevDK18rY",
        "outputId": "eff495c4-4529-4b2f-9b48-126785665d78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "execution_count": 335,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S44GmUZ12o-g"
      },
      "source": [
        "**Explain and discuss your results here:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ5HlDFAzGrH"
      },
      "source": [
        "### Part (g) -- 7%\n",
        "\n",
        "Find the optimial value of ${\\bf w}$ and $b$ using your code. Explain how you chose\n",
        "the learning rate $\\mu$ and the batch size. Show plots demostrating good and bad behaviours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dFOFSwgzGrI"
      },
      "source": [
        "w0 = np.random.randn(90)\n",
        "b0 = np.random.randn(1)[0]\n",
        "\n",
        "# Write your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkZt7_932zX2"
      },
      "source": [
        "**Explain and discuss your results here:**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KrQqSj2zGrI"
      },
      "source": [
        "### Part (h) -- 15%\n",
        "\n",
        "Using the values of `w` and `b` from part (g), compute your training accuracy, validation accuracy,\n",
        "and test accuracy. Are there any differences between those three values? If so, why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuKw2mLozGrI"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "train_acc = ...\n",
        "val_acc = ...\n",
        "test_acc = ...\n",
        "\n",
        "print('train_acc = ', train_acc, ' val_acc = ', val_acc, ' test_acc = ', test_acc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXZa1u6920M3"
      },
      "source": [
        "**Explain and discuss your results here:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4eP2Yh1zGrI"
      },
      "source": [
        "### Part (i) -- 15%\n",
        "\n",
        "Writing a classifier like this is instructive, and helps you understand what happens when\n",
        "we train a model. However, in practice, we rarely write model building and training code\n",
        "from scratch. Instead, we typically use one of the well-tested libraries available in a package.\n",
        "\n",
        "Use `sklearn.linear_model.LogisticRegression` to build a linear classifier, and make predictions about the test set. Start by reading the\n",
        "[API documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
        "\n",
        "Compute the training, validation and test accuracy of this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24LCfAa1zGrJ"
      },
      "source": [
        "import sklearn.linear_model\n",
        "\n",
        "model = ...\n",
        "\n",
        "train_acc = ...\n",
        "val_acc = ...\n",
        "test_acc = ...\n",
        "\n",
        "print('train_acc = ', train_acc, ' val_acc = ', val_acc, ' test_acc = ', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRqucdV923tG"
      },
      "source": [
        "**This parts helps by checking if the code worked.**\n",
        "**Check if you get similar results, if not repair your code**\n"
      ]
    }
  ]
}