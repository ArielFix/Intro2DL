{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArielFix/Intro2DL/blob/OnGoingAssignment1/Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bhfIKbQzGq2"
      },
      "source": [
        "# Assignment 1. Music Century Classification\n",
        "\n",
        "**Assignment Responsible**: Natalie Lang.\n",
        "\n",
        "In this assignment, we will build models to predict which\n",
        "**century** a piece of music was released.  We will be using the \"YearPredictionMSD Data Set\"\n",
        "based on the Million Song Dataset. The data is available to download from the UCI \n",
        "Machine Learning Repository. Here are some links about the data:\n",
        "\n",
        "- https://archive.ics.uci.edu/ml/datasets/yearpredictionmsd\n",
        "- http://millionsongdataset.com/pages/tasks-demos/#yearrecognition\n",
        "\n",
        "Note that you are note allowed to import additional packages **(especially not PyTorch)**. One of the objectives is to understand how the training procedure actually operates, before working with PyTorch's autograd engine which does it all for us.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47oq1vy5PUIV"
      },
      "source": [
        "## Question 1. Data (21%)\n",
        "\n",
        "Start by setting up a Google Colab notebook in which to do your work.\n",
        "Since you are working with a partner, you might find this link helpful:\n",
        "\n",
        "- https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb\n",
        "\n",
        "The recommended way to work together is pair coding, where you and your partner are sitting together and writing code together. \n",
        "\n",
        "To process and read the data, we use the popular `pandas` package for data analysis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aFWpuNSzGq9"
      },
      "source": [
        "import pandas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7UWL6mFzGq-"
      },
      "source": [
        "Now that your notebook is set up, we can load the data into the notebook. The code below provides\n",
        "two ways of loading the data: directly from the internet, or through mounting Google Drive.\n",
        "The first method is easier but slower, and the second method is a bit involved at first, but\n",
        "can save you time later on. You will need to mount Google Drive for later assignments, so we recommend\n",
        "figuring how to do that now.\n",
        "\n",
        "Here are some resources to help you get started:\n",
        "\n",
        "- http.://colab.research.google.com/notebooks/io.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY6PrfV4zGq_",
        "outputId": "f859bb38-d42c-4da9-e008-feb2a59c147b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "load_from_drive = True\n",
        "\n",
        "if not load_from_drive:\n",
        "  csv_path = \"http://archive.ics.uci.edu/ml/machine-learning-databases/00203/YearPredictionMSD.txt.zip\"\n",
        "else:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  csv_path = '/content/gdrive/My Drive/MSc/Courses/Into to Deep Learnig/Assignments/YearPredictionMSD.txt.zip' # TODO - UPDATE ME WITH THE TRUE PATH!\n",
        "\n",
        "t_label = [\"year\"]\n",
        "x_labels = [\"var%d\" % i for i in range(1, 91)]\n",
        "df = pandas.read_csv(csv_path, names=t_label + x_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgB83beNzGq_"
      },
      "source": [
        "Now that the data is loaded to your Colab notebook, you should be able to display the Pandas\n",
        "DataFrame `df` as a table:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5bBEnj3zGq_",
        "outputId": "3289fad9-ada2-43ca-ca8a-ada566dcdeb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        }
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        year      var1      var2      var3      var4      var5      var6  \\\n",
              "0       2001  49.94357  21.47114  73.07750   8.74861 -17.40628 -13.09905   \n",
              "1       2001  48.73215  18.42930  70.32679  12.94636 -10.32437 -24.83777   \n",
              "2       2001  50.95714  31.85602  55.81851  13.41693  -6.57898 -18.54940   \n",
              "3       2001  48.24750  -1.89837  36.29772   2.58776   0.97170 -26.21683   \n",
              "4       2001  50.97020  42.20998  67.09964   8.46791 -15.85279 -16.81409   \n",
              "...      ...       ...       ...       ...       ...       ...       ...   \n",
              "515340  2006  51.28467  45.88068  22.19582  -5.53319  -3.61835 -16.36914   \n",
              "515341  2006  49.87870  37.93125  18.65987  -3.63581 -27.75665 -18.52988   \n",
              "515342  2006  45.12852  12.65758 -38.72018   8.80882 -29.29985  -2.28706   \n",
              "515343  2006  44.16614  32.38368  -3.34971  -2.49165 -19.59278 -18.67098   \n",
              "515344  2005  51.85726  59.11655  26.39436  -5.46030 -20.69012 -19.95528   \n",
              "\n",
              "            var7      var8      var9  ...     var81      var82      var83  \\\n",
              "0      -25.01202 -12.23257   7.83089  ...  13.01620  -54.40548   58.99367   \n",
              "1        8.76630  -0.92019  18.76548  ...   5.66812  -19.68073   33.04964   \n",
              "2       -3.27872  -2.35035  16.07017  ...   3.03800   26.05866  -50.92779   \n",
              "3        5.05097 -10.34124   3.55005  ...  34.57337 -171.70734  -16.96705   \n",
              "4      -12.48207  -9.37636  12.63699  ...   9.92661  -55.95724   64.92712   \n",
              "...          ...       ...       ...  ...       ...        ...        ...   \n",
              "515340   2.12652   5.18160  -8.66890  ...   4.81440   -3.75991  -30.92584   \n",
              "515341   7.76108   3.56109  -2.50351  ...  32.38589  -32.75535  -61.05473   \n",
              "515342 -18.40424 -22.28726  -4.52429  ... -18.73598  -71.15954 -123.98443   \n",
              "515343   8.78428   4.02039 -12.01230  ...  67.16763  282.77624   -4.63677   \n",
              "515344  -6.72771   2.29590  10.31018  ... -11.50511  -69.18291   60.58456   \n",
              "\n",
              "            var84     var85     var86      var87     var88      var89  \\\n",
              "0        15.37344   1.11144 -23.08793   68.40795  -1.82223  -27.46348   \n",
              "1        42.87836  -9.90378 -32.22788   70.49388  12.04941   58.43453   \n",
              "2        10.93792  -0.07568  43.20130 -115.00698  -0.05859   39.67068   \n",
              "3       -46.67617 -12.51516  82.58061  -72.08993   9.90558  199.62971   \n",
              "4       -17.72522  -1.49237  -7.50035   51.76631   7.88713   55.66926   \n",
              "...           ...       ...       ...        ...       ...        ...   \n",
              "515340   26.33968  -5.03390  21.86037 -142.29410   3.42901  -41.14721   \n",
              "515341   56.65182  15.29965  95.88193  -10.63242  12.96552   92.11633   \n",
              "515342  121.26989  10.89629  34.62409 -248.61020  -6.07171   53.96319   \n",
              "515343  144.00125  21.62652 -29.72432   71.47198  20.32240   14.83107   \n",
              "515344   28.64599  -4.39620 -64.56491  -45.61012  -5.51512   32.35602   \n",
              "\n",
              "           var90  \n",
              "0        2.26327  \n",
              "1       26.92061  \n",
              "2       -0.66345  \n",
              "3       18.85382  \n",
              "4       28.74903  \n",
              "...          ...  \n",
              "515340 -15.46052  \n",
              "515341  10.88815  \n",
              "515342  -8.09364  \n",
              "515343  39.74909  \n",
              "515344  12.17352  \n",
              "\n",
              "[515345 rows x 91 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6ec64d16-d735-46d1-99f1-a1a95548f313\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>var1</th>\n",
              "      <th>var2</th>\n",
              "      <th>var3</th>\n",
              "      <th>var4</th>\n",
              "      <th>var5</th>\n",
              "      <th>var6</th>\n",
              "      <th>var7</th>\n",
              "      <th>var8</th>\n",
              "      <th>var9</th>\n",
              "      <th>...</th>\n",
              "      <th>var81</th>\n",
              "      <th>var82</th>\n",
              "      <th>var83</th>\n",
              "      <th>var84</th>\n",
              "      <th>var85</th>\n",
              "      <th>var86</th>\n",
              "      <th>var87</th>\n",
              "      <th>var88</th>\n",
              "      <th>var89</th>\n",
              "      <th>var90</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>49.94357</td>\n",
              "      <td>21.47114</td>\n",
              "      <td>73.07750</td>\n",
              "      <td>8.74861</td>\n",
              "      <td>-17.40628</td>\n",
              "      <td>-13.09905</td>\n",
              "      <td>-25.01202</td>\n",
              "      <td>-12.23257</td>\n",
              "      <td>7.83089</td>\n",
              "      <td>...</td>\n",
              "      <td>13.01620</td>\n",
              "      <td>-54.40548</td>\n",
              "      <td>58.99367</td>\n",
              "      <td>15.37344</td>\n",
              "      <td>1.11144</td>\n",
              "      <td>-23.08793</td>\n",
              "      <td>68.40795</td>\n",
              "      <td>-1.82223</td>\n",
              "      <td>-27.46348</td>\n",
              "      <td>2.26327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.73215</td>\n",
              "      <td>18.42930</td>\n",
              "      <td>70.32679</td>\n",
              "      <td>12.94636</td>\n",
              "      <td>-10.32437</td>\n",
              "      <td>-24.83777</td>\n",
              "      <td>8.76630</td>\n",
              "      <td>-0.92019</td>\n",
              "      <td>18.76548</td>\n",
              "      <td>...</td>\n",
              "      <td>5.66812</td>\n",
              "      <td>-19.68073</td>\n",
              "      <td>33.04964</td>\n",
              "      <td>42.87836</td>\n",
              "      <td>-9.90378</td>\n",
              "      <td>-32.22788</td>\n",
              "      <td>70.49388</td>\n",
              "      <td>12.04941</td>\n",
              "      <td>58.43453</td>\n",
              "      <td>26.92061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.95714</td>\n",
              "      <td>31.85602</td>\n",
              "      <td>55.81851</td>\n",
              "      <td>13.41693</td>\n",
              "      <td>-6.57898</td>\n",
              "      <td>-18.54940</td>\n",
              "      <td>-3.27872</td>\n",
              "      <td>-2.35035</td>\n",
              "      <td>16.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>3.03800</td>\n",
              "      <td>26.05866</td>\n",
              "      <td>-50.92779</td>\n",
              "      <td>10.93792</td>\n",
              "      <td>-0.07568</td>\n",
              "      <td>43.20130</td>\n",
              "      <td>-115.00698</td>\n",
              "      <td>-0.05859</td>\n",
              "      <td>39.67068</td>\n",
              "      <td>-0.66345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.24750</td>\n",
              "      <td>-1.89837</td>\n",
              "      <td>36.29772</td>\n",
              "      <td>2.58776</td>\n",
              "      <td>0.97170</td>\n",
              "      <td>-26.21683</td>\n",
              "      <td>5.05097</td>\n",
              "      <td>-10.34124</td>\n",
              "      <td>3.55005</td>\n",
              "      <td>...</td>\n",
              "      <td>34.57337</td>\n",
              "      <td>-171.70734</td>\n",
              "      <td>-16.96705</td>\n",
              "      <td>-46.67617</td>\n",
              "      <td>-12.51516</td>\n",
              "      <td>82.58061</td>\n",
              "      <td>-72.08993</td>\n",
              "      <td>9.90558</td>\n",
              "      <td>199.62971</td>\n",
              "      <td>18.85382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.97020</td>\n",
              "      <td>42.20998</td>\n",
              "      <td>67.09964</td>\n",
              "      <td>8.46791</td>\n",
              "      <td>-15.85279</td>\n",
              "      <td>-16.81409</td>\n",
              "      <td>-12.48207</td>\n",
              "      <td>-9.37636</td>\n",
              "      <td>12.63699</td>\n",
              "      <td>...</td>\n",
              "      <td>9.92661</td>\n",
              "      <td>-55.95724</td>\n",
              "      <td>64.92712</td>\n",
              "      <td>-17.72522</td>\n",
              "      <td>-1.49237</td>\n",
              "      <td>-7.50035</td>\n",
              "      <td>51.76631</td>\n",
              "      <td>7.88713</td>\n",
              "      <td>55.66926</td>\n",
              "      <td>28.74903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515340</th>\n",
              "      <td>2006</td>\n",
              "      <td>51.28467</td>\n",
              "      <td>45.88068</td>\n",
              "      <td>22.19582</td>\n",
              "      <td>-5.53319</td>\n",
              "      <td>-3.61835</td>\n",
              "      <td>-16.36914</td>\n",
              "      <td>2.12652</td>\n",
              "      <td>5.18160</td>\n",
              "      <td>-8.66890</td>\n",
              "      <td>...</td>\n",
              "      <td>4.81440</td>\n",
              "      <td>-3.75991</td>\n",
              "      <td>-30.92584</td>\n",
              "      <td>26.33968</td>\n",
              "      <td>-5.03390</td>\n",
              "      <td>21.86037</td>\n",
              "      <td>-142.29410</td>\n",
              "      <td>3.42901</td>\n",
              "      <td>-41.14721</td>\n",
              "      <td>-15.46052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515341</th>\n",
              "      <td>2006</td>\n",
              "      <td>49.87870</td>\n",
              "      <td>37.93125</td>\n",
              "      <td>18.65987</td>\n",
              "      <td>-3.63581</td>\n",
              "      <td>-27.75665</td>\n",
              "      <td>-18.52988</td>\n",
              "      <td>7.76108</td>\n",
              "      <td>3.56109</td>\n",
              "      <td>-2.50351</td>\n",
              "      <td>...</td>\n",
              "      <td>32.38589</td>\n",
              "      <td>-32.75535</td>\n",
              "      <td>-61.05473</td>\n",
              "      <td>56.65182</td>\n",
              "      <td>15.29965</td>\n",
              "      <td>95.88193</td>\n",
              "      <td>-10.63242</td>\n",
              "      <td>12.96552</td>\n",
              "      <td>92.11633</td>\n",
              "      <td>10.88815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515342</th>\n",
              "      <td>2006</td>\n",
              "      <td>45.12852</td>\n",
              "      <td>12.65758</td>\n",
              "      <td>-38.72018</td>\n",
              "      <td>8.80882</td>\n",
              "      <td>-29.29985</td>\n",
              "      <td>-2.28706</td>\n",
              "      <td>-18.40424</td>\n",
              "      <td>-22.28726</td>\n",
              "      <td>-4.52429</td>\n",
              "      <td>...</td>\n",
              "      <td>-18.73598</td>\n",
              "      <td>-71.15954</td>\n",
              "      <td>-123.98443</td>\n",
              "      <td>121.26989</td>\n",
              "      <td>10.89629</td>\n",
              "      <td>34.62409</td>\n",
              "      <td>-248.61020</td>\n",
              "      <td>-6.07171</td>\n",
              "      <td>53.96319</td>\n",
              "      <td>-8.09364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515343</th>\n",
              "      <td>2006</td>\n",
              "      <td>44.16614</td>\n",
              "      <td>32.38368</td>\n",
              "      <td>-3.34971</td>\n",
              "      <td>-2.49165</td>\n",
              "      <td>-19.59278</td>\n",
              "      <td>-18.67098</td>\n",
              "      <td>8.78428</td>\n",
              "      <td>4.02039</td>\n",
              "      <td>-12.01230</td>\n",
              "      <td>...</td>\n",
              "      <td>67.16763</td>\n",
              "      <td>282.77624</td>\n",
              "      <td>-4.63677</td>\n",
              "      <td>144.00125</td>\n",
              "      <td>21.62652</td>\n",
              "      <td>-29.72432</td>\n",
              "      <td>71.47198</td>\n",
              "      <td>20.32240</td>\n",
              "      <td>14.83107</td>\n",
              "      <td>39.74909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515344</th>\n",
              "      <td>2005</td>\n",
              "      <td>51.85726</td>\n",
              "      <td>59.11655</td>\n",
              "      <td>26.39436</td>\n",
              "      <td>-5.46030</td>\n",
              "      <td>-20.69012</td>\n",
              "      <td>-19.95528</td>\n",
              "      <td>-6.72771</td>\n",
              "      <td>2.29590</td>\n",
              "      <td>10.31018</td>\n",
              "      <td>...</td>\n",
              "      <td>-11.50511</td>\n",
              "      <td>-69.18291</td>\n",
              "      <td>60.58456</td>\n",
              "      <td>28.64599</td>\n",
              "      <td>-4.39620</td>\n",
              "      <td>-64.56491</td>\n",
              "      <td>-45.61012</td>\n",
              "      <td>-5.51512</td>\n",
              "      <td>32.35602</td>\n",
              "      <td>12.17352</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>515345 rows × 91 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ec64d16-d735-46d1-99f1-a1a95548f313')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6ec64d16-d735-46d1-99f1-a1a95548f313 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6ec64d16-d735-46d1-99f1-a1a95548f313');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaLuAMH_zGrA"
      },
      "source": [
        "To set up our data for classification, we'll use the \"year\" field to represent\n",
        "whether a song was released in the 20-th century. In our case `df[\"year\"]` will be 1 if\n",
        "the year was released after 2000, and 0 otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZdGlNgdzGrA"
      },
      "source": [
        "df[\"year\"] = df[\"year\"].map(lambda x: int(x > 2000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xugy7FZ8eoAd",
        "outputId": "9422226d-0186-43b4-cac9-d484531dd08a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        }
      },
      "source": [
        "df.head(20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    year      var1       var2      var3      var4      var5      var6  \\\n",
              "0      1  49.94357   21.47114  73.07750   8.74861 -17.40628 -13.09905   \n",
              "1      1  48.73215   18.42930  70.32679  12.94636 -10.32437 -24.83777   \n",
              "2      1  50.95714   31.85602  55.81851  13.41693  -6.57898 -18.54940   \n",
              "3      1  48.24750   -1.89837  36.29772   2.58776   0.97170 -26.21683   \n",
              "4      1  50.97020   42.20998  67.09964   8.46791 -15.85279 -16.81409   \n",
              "5      1  50.54767    0.31568  92.35066  22.38696 -25.51870 -19.04928   \n",
              "6      1  50.57546   33.17843  50.53517  11.55217 -27.24764  -8.78206   \n",
              "7      1  48.26892    8.97526  75.23158  24.04945 -16.02105 -14.09491   \n",
              "8      1  49.75468   33.99581  56.73846   2.89581  -2.92429 -26.44413   \n",
              "9      1  45.17809   46.34234 -40.65357  -2.47909   1.21253  -0.65302   \n",
              "10     1  39.13076  -23.01763 -36.20583   1.67519  -4.27101  13.01158   \n",
              "11     1  37.66498  -34.05910 -17.36060 -26.77781 -39.95119 -20.75000   \n",
              "12     1  26.51957 -148.15762 -13.30095  -7.25851  17.22029 -21.99439   \n",
              "13     1  37.68491  -26.84185 -27.10566 -14.95883  -5.87200 -21.68979   \n",
              "14     0  39.11695   -8.29767 -51.37966  -4.42668 -30.06506 -11.95916   \n",
              "15     1  35.05129  -67.97714 -14.20239  -6.68696  -0.61230 -18.70341   \n",
              "16     1  33.63129  -96.14912 -89.38216 -12.11699  13.77252  -6.69377   \n",
              "17     0  41.38639  -20.78665  51.80155  17.21415 -36.44189 -11.53169   \n",
              "18     0  37.45034   11.42615  56.28982  19.58426 -16.43530   2.22457   \n",
              "19     0  39.71092   -4.92800  12.88590 -11.87773   2.48031 -16.11028   \n",
              "\n",
              "        var7      var8      var9  ...     var81      var82      var83  \\\n",
              "0  -25.01202 -12.23257   7.83089  ...  13.01620  -54.40548   58.99367   \n",
              "1    8.76630  -0.92019  18.76548  ...   5.66812  -19.68073   33.04964   \n",
              "2   -3.27872  -2.35035  16.07017  ...   3.03800   26.05866  -50.92779   \n",
              "3    5.05097 -10.34124   3.55005  ...  34.57337 -171.70734  -16.96705   \n",
              "4  -12.48207  -9.37636  12.63699  ...   9.92661  -55.95724   64.92712   \n",
              "5   20.67345  -5.19943   3.63566  ...   6.59753  -50.69577   26.02574   \n",
              "6  -12.04282  -9.53930  28.61811  ...  11.63681   25.44182  134.62382   \n",
              "7    8.11871  -1.87566   7.46701  ...  18.03989  -58.46192  -65.56438   \n",
              "8    1.71392  -0.55644  22.08594  ...  18.70812    5.20391  -27.75192   \n",
              "9   -6.95536 -12.20040  17.02512  ...  -4.36742  -87.55285  -70.79677   \n",
              "10   8.05718  -8.41088   6.27370  ...  32.86051  -26.08461 -186.82429   \n",
              "11  -0.10231  -0.89972  -1.30205  ...  11.18909   45.20614   53.83925   \n",
              "12   5.51947   3.48418   2.61738  ...  23.80442  251.76360   18.81642   \n",
              "13   4.87374 -18.01800   1.52141  ... -67.57637  234.27192  -72.34557   \n",
              "14  -0.85322  -8.86179  11.36680  ...  42.22923  478.26580  -10.33823   \n",
              "15  -1.31928  -9.46370   5.53492  ...  10.25585   94.90539   15.95689   \n",
              "16 -33.36843 -24.81437  21.22757  ...  49.93249  -14.47489   40.70590   \n",
              "17  11.75252  -7.62428  -3.65488  ...  50.37614  -40.48205   48.07805   \n",
              "18   1.02668  -7.34736  -0.01184  ... -22.46207  -25.77228 -322.42841   \n",
              "19 -16.40421  -8.29657   9.86817  ...  11.92816  -73.72412   16.19039   \n",
              "\n",
              "        var84     var85      var86      var87     var88       var89     var90  \n",
              "0    15.37344   1.11144  -23.08793   68.40795  -1.82223   -27.46348   2.26327  \n",
              "1    42.87836  -9.90378  -32.22788   70.49388  12.04941    58.43453  26.92061  \n",
              "2    10.93792  -0.07568   43.20130 -115.00698  -0.05859    39.67068  -0.66345  \n",
              "3   -46.67617 -12.51516   82.58061  -72.08993   9.90558   199.62971  18.85382  \n",
              "4   -17.72522  -1.49237   -7.50035   51.76631   7.88713    55.66926  28.74903  \n",
              "5    18.94430  -0.33730    6.09352   35.18381   5.00283   -11.02257   0.02263  \n",
              "6    21.51982   8.17570   35.46251   11.57736   4.50056    -4.62739   1.40192  \n",
              "7    46.99856  -4.09602   56.37650  -18.29975  -0.30633     3.98364  -3.72556  \n",
              "8    17.22100  -0.85210  -15.67150  -26.36257   5.48708    -9.13495   6.08680  \n",
              "9    76.57355  -7.71727    3.26926 -298.49845  11.49326   -89.21804 -15.09719  \n",
              "10  113.58176   9.28727   44.60282  158.00425  -2.59543   109.19723  23.36143  \n",
              "11    2.59467  -4.00958  -47.74886 -170.92864  -5.19009     8.83617  -7.16056  \n",
              "12  157.09656 -27.79449 -137.72740  115.28414  23.00230  -164.02536  51.54138  \n",
              "13 -362.25101 -25.55019  -89.08971 -891.58937  14.11648 -1030.99180  99.28967  \n",
              "14 -103.76858  39.19511  -98.76636 -122.81061  -2.14942  -211.48202 -12.81569  \n",
              "15  -98.15732  -9.64859  -93.52834  -95.82981  20.73063  -562.07671  43.44696  \n",
              "16   58.63692   8.81522   27.28474    5.78046   3.44539   259.10825  10.28525  \n",
              "17   -7.62399   6.51934  -30.46090  -53.87264   4.44627    58.16913  -0.02409  \n",
              "18 -146.57408  13.61588   92.22918 -439.80259  25.73235   157.22967  38.70617  \n",
              "19    9.79606   9.71693   -9.90907  -20.65851   2.34002   -31.57015   1.58400  \n",
              "\n",
              "[20 rows x 91 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-695d2b2e-c986-4a39-83c5-fa65f8184433\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>var1</th>\n",
              "      <th>var2</th>\n",
              "      <th>var3</th>\n",
              "      <th>var4</th>\n",
              "      <th>var5</th>\n",
              "      <th>var6</th>\n",
              "      <th>var7</th>\n",
              "      <th>var8</th>\n",
              "      <th>var9</th>\n",
              "      <th>...</th>\n",
              "      <th>var81</th>\n",
              "      <th>var82</th>\n",
              "      <th>var83</th>\n",
              "      <th>var84</th>\n",
              "      <th>var85</th>\n",
              "      <th>var86</th>\n",
              "      <th>var87</th>\n",
              "      <th>var88</th>\n",
              "      <th>var89</th>\n",
              "      <th>var90</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>49.94357</td>\n",
              "      <td>21.47114</td>\n",
              "      <td>73.07750</td>\n",
              "      <td>8.74861</td>\n",
              "      <td>-17.40628</td>\n",
              "      <td>-13.09905</td>\n",
              "      <td>-25.01202</td>\n",
              "      <td>-12.23257</td>\n",
              "      <td>7.83089</td>\n",
              "      <td>...</td>\n",
              "      <td>13.01620</td>\n",
              "      <td>-54.40548</td>\n",
              "      <td>58.99367</td>\n",
              "      <td>15.37344</td>\n",
              "      <td>1.11144</td>\n",
              "      <td>-23.08793</td>\n",
              "      <td>68.40795</td>\n",
              "      <td>-1.82223</td>\n",
              "      <td>-27.46348</td>\n",
              "      <td>2.26327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>48.73215</td>\n",
              "      <td>18.42930</td>\n",
              "      <td>70.32679</td>\n",
              "      <td>12.94636</td>\n",
              "      <td>-10.32437</td>\n",
              "      <td>-24.83777</td>\n",
              "      <td>8.76630</td>\n",
              "      <td>-0.92019</td>\n",
              "      <td>18.76548</td>\n",
              "      <td>...</td>\n",
              "      <td>5.66812</td>\n",
              "      <td>-19.68073</td>\n",
              "      <td>33.04964</td>\n",
              "      <td>42.87836</td>\n",
              "      <td>-9.90378</td>\n",
              "      <td>-32.22788</td>\n",
              "      <td>70.49388</td>\n",
              "      <td>12.04941</td>\n",
              "      <td>58.43453</td>\n",
              "      <td>26.92061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>50.95714</td>\n",
              "      <td>31.85602</td>\n",
              "      <td>55.81851</td>\n",
              "      <td>13.41693</td>\n",
              "      <td>-6.57898</td>\n",
              "      <td>-18.54940</td>\n",
              "      <td>-3.27872</td>\n",
              "      <td>-2.35035</td>\n",
              "      <td>16.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>3.03800</td>\n",
              "      <td>26.05866</td>\n",
              "      <td>-50.92779</td>\n",
              "      <td>10.93792</td>\n",
              "      <td>-0.07568</td>\n",
              "      <td>43.20130</td>\n",
              "      <td>-115.00698</td>\n",
              "      <td>-0.05859</td>\n",
              "      <td>39.67068</td>\n",
              "      <td>-0.66345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>48.24750</td>\n",
              "      <td>-1.89837</td>\n",
              "      <td>36.29772</td>\n",
              "      <td>2.58776</td>\n",
              "      <td>0.97170</td>\n",
              "      <td>-26.21683</td>\n",
              "      <td>5.05097</td>\n",
              "      <td>-10.34124</td>\n",
              "      <td>3.55005</td>\n",
              "      <td>...</td>\n",
              "      <td>34.57337</td>\n",
              "      <td>-171.70734</td>\n",
              "      <td>-16.96705</td>\n",
              "      <td>-46.67617</td>\n",
              "      <td>-12.51516</td>\n",
              "      <td>82.58061</td>\n",
              "      <td>-72.08993</td>\n",
              "      <td>9.90558</td>\n",
              "      <td>199.62971</td>\n",
              "      <td>18.85382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50.97020</td>\n",
              "      <td>42.20998</td>\n",
              "      <td>67.09964</td>\n",
              "      <td>8.46791</td>\n",
              "      <td>-15.85279</td>\n",
              "      <td>-16.81409</td>\n",
              "      <td>-12.48207</td>\n",
              "      <td>-9.37636</td>\n",
              "      <td>12.63699</td>\n",
              "      <td>...</td>\n",
              "      <td>9.92661</td>\n",
              "      <td>-55.95724</td>\n",
              "      <td>64.92712</td>\n",
              "      <td>-17.72522</td>\n",
              "      <td>-1.49237</td>\n",
              "      <td>-7.50035</td>\n",
              "      <td>51.76631</td>\n",
              "      <td>7.88713</td>\n",
              "      <td>55.66926</td>\n",
              "      <td>28.74903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>50.54767</td>\n",
              "      <td>0.31568</td>\n",
              "      <td>92.35066</td>\n",
              "      <td>22.38696</td>\n",
              "      <td>-25.51870</td>\n",
              "      <td>-19.04928</td>\n",
              "      <td>20.67345</td>\n",
              "      <td>-5.19943</td>\n",
              "      <td>3.63566</td>\n",
              "      <td>...</td>\n",
              "      <td>6.59753</td>\n",
              "      <td>-50.69577</td>\n",
              "      <td>26.02574</td>\n",
              "      <td>18.94430</td>\n",
              "      <td>-0.33730</td>\n",
              "      <td>6.09352</td>\n",
              "      <td>35.18381</td>\n",
              "      <td>5.00283</td>\n",
              "      <td>-11.02257</td>\n",
              "      <td>0.02263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>50.57546</td>\n",
              "      <td>33.17843</td>\n",
              "      <td>50.53517</td>\n",
              "      <td>11.55217</td>\n",
              "      <td>-27.24764</td>\n",
              "      <td>-8.78206</td>\n",
              "      <td>-12.04282</td>\n",
              "      <td>-9.53930</td>\n",
              "      <td>28.61811</td>\n",
              "      <td>...</td>\n",
              "      <td>11.63681</td>\n",
              "      <td>25.44182</td>\n",
              "      <td>134.62382</td>\n",
              "      <td>21.51982</td>\n",
              "      <td>8.17570</td>\n",
              "      <td>35.46251</td>\n",
              "      <td>11.57736</td>\n",
              "      <td>4.50056</td>\n",
              "      <td>-4.62739</td>\n",
              "      <td>1.40192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>48.26892</td>\n",
              "      <td>8.97526</td>\n",
              "      <td>75.23158</td>\n",
              "      <td>24.04945</td>\n",
              "      <td>-16.02105</td>\n",
              "      <td>-14.09491</td>\n",
              "      <td>8.11871</td>\n",
              "      <td>-1.87566</td>\n",
              "      <td>7.46701</td>\n",
              "      <td>...</td>\n",
              "      <td>18.03989</td>\n",
              "      <td>-58.46192</td>\n",
              "      <td>-65.56438</td>\n",
              "      <td>46.99856</td>\n",
              "      <td>-4.09602</td>\n",
              "      <td>56.37650</td>\n",
              "      <td>-18.29975</td>\n",
              "      <td>-0.30633</td>\n",
              "      <td>3.98364</td>\n",
              "      <td>-3.72556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>49.75468</td>\n",
              "      <td>33.99581</td>\n",
              "      <td>56.73846</td>\n",
              "      <td>2.89581</td>\n",
              "      <td>-2.92429</td>\n",
              "      <td>-26.44413</td>\n",
              "      <td>1.71392</td>\n",
              "      <td>-0.55644</td>\n",
              "      <td>22.08594</td>\n",
              "      <td>...</td>\n",
              "      <td>18.70812</td>\n",
              "      <td>5.20391</td>\n",
              "      <td>-27.75192</td>\n",
              "      <td>17.22100</td>\n",
              "      <td>-0.85210</td>\n",
              "      <td>-15.67150</td>\n",
              "      <td>-26.36257</td>\n",
              "      <td>5.48708</td>\n",
              "      <td>-9.13495</td>\n",
              "      <td>6.08680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>45.17809</td>\n",
              "      <td>46.34234</td>\n",
              "      <td>-40.65357</td>\n",
              "      <td>-2.47909</td>\n",
              "      <td>1.21253</td>\n",
              "      <td>-0.65302</td>\n",
              "      <td>-6.95536</td>\n",
              "      <td>-12.20040</td>\n",
              "      <td>17.02512</td>\n",
              "      <td>...</td>\n",
              "      <td>-4.36742</td>\n",
              "      <td>-87.55285</td>\n",
              "      <td>-70.79677</td>\n",
              "      <td>76.57355</td>\n",
              "      <td>-7.71727</td>\n",
              "      <td>3.26926</td>\n",
              "      <td>-298.49845</td>\n",
              "      <td>11.49326</td>\n",
              "      <td>-89.21804</td>\n",
              "      <td>-15.09719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>1</td>\n",
              "      <td>39.13076</td>\n",
              "      <td>-23.01763</td>\n",
              "      <td>-36.20583</td>\n",
              "      <td>1.67519</td>\n",
              "      <td>-4.27101</td>\n",
              "      <td>13.01158</td>\n",
              "      <td>8.05718</td>\n",
              "      <td>-8.41088</td>\n",
              "      <td>6.27370</td>\n",
              "      <td>...</td>\n",
              "      <td>32.86051</td>\n",
              "      <td>-26.08461</td>\n",
              "      <td>-186.82429</td>\n",
              "      <td>113.58176</td>\n",
              "      <td>9.28727</td>\n",
              "      <td>44.60282</td>\n",
              "      <td>158.00425</td>\n",
              "      <td>-2.59543</td>\n",
              "      <td>109.19723</td>\n",
              "      <td>23.36143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>37.66498</td>\n",
              "      <td>-34.05910</td>\n",
              "      <td>-17.36060</td>\n",
              "      <td>-26.77781</td>\n",
              "      <td>-39.95119</td>\n",
              "      <td>-20.75000</td>\n",
              "      <td>-0.10231</td>\n",
              "      <td>-0.89972</td>\n",
              "      <td>-1.30205</td>\n",
              "      <td>...</td>\n",
              "      <td>11.18909</td>\n",
              "      <td>45.20614</td>\n",
              "      <td>53.83925</td>\n",
              "      <td>2.59467</td>\n",
              "      <td>-4.00958</td>\n",
              "      <td>-47.74886</td>\n",
              "      <td>-170.92864</td>\n",
              "      <td>-5.19009</td>\n",
              "      <td>8.83617</td>\n",
              "      <td>-7.16056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>26.51957</td>\n",
              "      <td>-148.15762</td>\n",
              "      <td>-13.30095</td>\n",
              "      <td>-7.25851</td>\n",
              "      <td>17.22029</td>\n",
              "      <td>-21.99439</td>\n",
              "      <td>5.51947</td>\n",
              "      <td>3.48418</td>\n",
              "      <td>2.61738</td>\n",
              "      <td>...</td>\n",
              "      <td>23.80442</td>\n",
              "      <td>251.76360</td>\n",
              "      <td>18.81642</td>\n",
              "      <td>157.09656</td>\n",
              "      <td>-27.79449</td>\n",
              "      <td>-137.72740</td>\n",
              "      <td>115.28414</td>\n",
              "      <td>23.00230</td>\n",
              "      <td>-164.02536</td>\n",
              "      <td>51.54138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>37.68491</td>\n",
              "      <td>-26.84185</td>\n",
              "      <td>-27.10566</td>\n",
              "      <td>-14.95883</td>\n",
              "      <td>-5.87200</td>\n",
              "      <td>-21.68979</td>\n",
              "      <td>4.87374</td>\n",
              "      <td>-18.01800</td>\n",
              "      <td>1.52141</td>\n",
              "      <td>...</td>\n",
              "      <td>-67.57637</td>\n",
              "      <td>234.27192</td>\n",
              "      <td>-72.34557</td>\n",
              "      <td>-362.25101</td>\n",
              "      <td>-25.55019</td>\n",
              "      <td>-89.08971</td>\n",
              "      <td>-891.58937</td>\n",
              "      <td>14.11648</td>\n",
              "      <td>-1030.99180</td>\n",
              "      <td>99.28967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>39.11695</td>\n",
              "      <td>-8.29767</td>\n",
              "      <td>-51.37966</td>\n",
              "      <td>-4.42668</td>\n",
              "      <td>-30.06506</td>\n",
              "      <td>-11.95916</td>\n",
              "      <td>-0.85322</td>\n",
              "      <td>-8.86179</td>\n",
              "      <td>11.36680</td>\n",
              "      <td>...</td>\n",
              "      <td>42.22923</td>\n",
              "      <td>478.26580</td>\n",
              "      <td>-10.33823</td>\n",
              "      <td>-103.76858</td>\n",
              "      <td>39.19511</td>\n",
              "      <td>-98.76636</td>\n",
              "      <td>-122.81061</td>\n",
              "      <td>-2.14942</td>\n",
              "      <td>-211.48202</td>\n",
              "      <td>-12.81569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>1</td>\n",
              "      <td>35.05129</td>\n",
              "      <td>-67.97714</td>\n",
              "      <td>-14.20239</td>\n",
              "      <td>-6.68696</td>\n",
              "      <td>-0.61230</td>\n",
              "      <td>-18.70341</td>\n",
              "      <td>-1.31928</td>\n",
              "      <td>-9.46370</td>\n",
              "      <td>5.53492</td>\n",
              "      <td>...</td>\n",
              "      <td>10.25585</td>\n",
              "      <td>94.90539</td>\n",
              "      <td>15.95689</td>\n",
              "      <td>-98.15732</td>\n",
              "      <td>-9.64859</td>\n",
              "      <td>-93.52834</td>\n",
              "      <td>-95.82981</td>\n",
              "      <td>20.73063</td>\n",
              "      <td>-562.07671</td>\n",
              "      <td>43.44696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>33.63129</td>\n",
              "      <td>-96.14912</td>\n",
              "      <td>-89.38216</td>\n",
              "      <td>-12.11699</td>\n",
              "      <td>13.77252</td>\n",
              "      <td>-6.69377</td>\n",
              "      <td>-33.36843</td>\n",
              "      <td>-24.81437</td>\n",
              "      <td>21.22757</td>\n",
              "      <td>...</td>\n",
              "      <td>49.93249</td>\n",
              "      <td>-14.47489</td>\n",
              "      <td>40.70590</td>\n",
              "      <td>58.63692</td>\n",
              "      <td>8.81522</td>\n",
              "      <td>27.28474</td>\n",
              "      <td>5.78046</td>\n",
              "      <td>3.44539</td>\n",
              "      <td>259.10825</td>\n",
              "      <td>10.28525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>41.38639</td>\n",
              "      <td>-20.78665</td>\n",
              "      <td>51.80155</td>\n",
              "      <td>17.21415</td>\n",
              "      <td>-36.44189</td>\n",
              "      <td>-11.53169</td>\n",
              "      <td>11.75252</td>\n",
              "      <td>-7.62428</td>\n",
              "      <td>-3.65488</td>\n",
              "      <td>...</td>\n",
              "      <td>50.37614</td>\n",
              "      <td>-40.48205</td>\n",
              "      <td>48.07805</td>\n",
              "      <td>-7.62399</td>\n",
              "      <td>6.51934</td>\n",
              "      <td>-30.46090</td>\n",
              "      <td>-53.87264</td>\n",
              "      <td>4.44627</td>\n",
              "      <td>58.16913</td>\n",
              "      <td>-0.02409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>37.45034</td>\n",
              "      <td>11.42615</td>\n",
              "      <td>56.28982</td>\n",
              "      <td>19.58426</td>\n",
              "      <td>-16.43530</td>\n",
              "      <td>2.22457</td>\n",
              "      <td>1.02668</td>\n",
              "      <td>-7.34736</td>\n",
              "      <td>-0.01184</td>\n",
              "      <td>...</td>\n",
              "      <td>-22.46207</td>\n",
              "      <td>-25.77228</td>\n",
              "      <td>-322.42841</td>\n",
              "      <td>-146.57408</td>\n",
              "      <td>13.61588</td>\n",
              "      <td>92.22918</td>\n",
              "      <td>-439.80259</td>\n",
              "      <td>25.73235</td>\n",
              "      <td>157.22967</td>\n",
              "      <td>38.70617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>39.71092</td>\n",
              "      <td>-4.92800</td>\n",
              "      <td>12.88590</td>\n",
              "      <td>-11.87773</td>\n",
              "      <td>2.48031</td>\n",
              "      <td>-16.11028</td>\n",
              "      <td>-16.40421</td>\n",
              "      <td>-8.29657</td>\n",
              "      <td>9.86817</td>\n",
              "      <td>...</td>\n",
              "      <td>11.92816</td>\n",
              "      <td>-73.72412</td>\n",
              "      <td>16.19039</td>\n",
              "      <td>9.79606</td>\n",
              "      <td>9.71693</td>\n",
              "      <td>-9.90907</td>\n",
              "      <td>-20.65851</td>\n",
              "      <td>2.34002</td>\n",
              "      <td>-31.57015</td>\n",
              "      <td>1.58400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20 rows × 91 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-695d2b2e-c986-4a39-83c5-fa65f8184433')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-695d2b2e-c986-4a39-83c5-fa65f8184433 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-695d2b2e-c986-4a39-83c5-fa65f8184433');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncjxI4WdzGrA"
      },
      "source": [
        "### Part (a) -- 7%\n",
        "\n",
        "The data set description text asks us to respect the below train/test split to\n",
        "avoid the \"producer effect\". That is, we want to make sure that no song from a single artist\n",
        "ends up in both the training and test set.\n",
        "\n",
        "Explain why it would be problematic to have\n",
        "some songs from an artist in the training set, and other songs from the same artist in the\n",
        "test set. (Hint: Remember that we want our test accuracy to predict how well the model\n",
        "will perform in practice on a song it hasn't learned about.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NiYlxpFzGrB"
      },
      "source": [
        "df_train = df[:463715]\n",
        "df_test = df[463715:]\n",
        "\n",
        "# convert to numpy\n",
        "train_xs = df_train[x_labels].to_numpy()\n",
        "train_ts = df_train[t_label].to_numpy()\n",
        "test_xs = df_test[x_labels].to_numpy()\n",
        "test_ts = df_test[t_label].to_numpy()\n",
        "\n",
        "# Write your explanation here\n",
        "\n",
        "# Songs from the same artist might have the same features due to the artist style.\n",
        "# In order to test our model predictions for general data, test set must include data that wasn't in the train set, otherwise,\n",
        "# we might have an overfit due to the producer effect and it will seem like good results on the test because the model overfitted to similar data.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYSzd4XUzGrB"
      },
      "source": [
        "### Part (b) -- 7%\n",
        "\n",
        "It can be beneficial to **normalize** the columns, so that each column (feature)\n",
        "has the *same* mean and standard deviation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPuWLksJzGrB"
      },
      "source": [
        "feature_means = df_train.mean()[1:].to_numpy() # the [1:] removes the mean of the \"year\" field\n",
        "feature_stds  = df_train.std()[1:].to_numpy()\n",
        "\n",
        "train_norm_xs = (train_xs - feature_means) / feature_stds\n",
        "test_norm_xs = (test_xs - feature_means) / feature_stds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4zmZk6ezGrC"
      },
      "source": [
        "Notice how in our code, we normalized the test set using the *training data means and standard deviations*.\n",
        "This is *not* a bug.\n",
        "\n",
        "Explain why it would be improper to compute and use test set means\n",
        "and standard deviations. (Hint: Remember what we want to use the test accuracy to measure.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxZy6brwzGrC"
      },
      "source": [
        "# Write your explanation here\n",
        "\n",
        "# We will use our test to measure the model accuracy on new data (which might not be in a set/ batch) and will test it predictions according to the\n",
        "# learned parameters during the training.\n",
        "# during inference (predictions) we will use the mean and standard deviation of the train so in order for the test\n",
        "# to represent the model accuracy during inference it shoukd use the same parameters.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4GqL5J_zGrC"
      },
      "source": [
        "### Part (c) -- 7%\n",
        "\n",
        "Finally, we'll move some of the data in our training set into a validation set.\n",
        "\n",
        "Explain why we should limit how many times we use the test set, and that we should use the validation\n",
        "set during the model building process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsXv1U3gzGrC"
      },
      "source": [
        "# shuffle the training set\n",
        "reindex = np.random.permutation(len(train_xs))\n",
        "train_xs = train_xs[reindex]\n",
        "train_norm_xs = train_norm_xs[reindex]\n",
        "train_ts = train_ts[reindex]\n",
        "\n",
        "# use the first 50000 elements of `train_xs` as the validation set\n",
        "train_xs, val_xs           = train_xs[50000:], train_xs[:50000]\n",
        "train_norm_xs, val_norm_xs = train_norm_xs[50000:], train_norm_xs[:50000]\n",
        "train_ts, val_ts           = train_ts[50000:], train_ts[:50000]\n",
        "\n",
        "# Write your explanation here\n",
        "\n",
        "# in order for the test set to represent how well the model will perform on new data' we should be sure that we test it with a new data which wasn't a part\n",
        "# of the training considerations, hence, the test set should be used only once at the end of the process to verify the model accuracy.\n",
        "# due to the need of hyper parameters tunung and feature engineering during the model training process in order to get the best model,\n",
        "# we are splitting our train set to train and validation.\n",
        "# The validation set will be used as a test set for determining the hyper parameters and test set will be used for testing our final trained model when hyper parameters and\n",
        "# features are final\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy4lt445zGrD"
      },
      "source": [
        "## Part 2. Classification (79%)\n",
        "\n",
        "We will first build a *classification* model to perform decade classification.\n",
        "These helper functions are written for you. All other code that you write in this section should be vectorized whenever possible (i.e., avoid unnecessary loops)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6BA_s-kzGrD"
      },
      "source": [
        "def sigmoid(z):\n",
        "  return 1 / (1 + np.exp(-z))\n",
        "    \n",
        "def cross_entropy(t, y):\n",
        "  return -t * np.log(y + np.finfo(float).eps) - (1 - t) * np.log(1 - y + np.finfo(float).eps)\n",
        "\n",
        "def cost(y, t):\n",
        "  return np.mean(cross_entropy(t, y))\n",
        "\n",
        "def get_accuracy(y, t):\n",
        "  acc = 0\n",
        "  N = 0\n",
        "  for i in range(len(y)):\n",
        "    N += 1\n",
        "    if (y[i] >= 0.5 and t[i] == 1) or (y[i] < 0.5 and t[i] == 0):\n",
        "      acc += 1\n",
        "  return acc / N"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8ZIfooBzGrD"
      },
      "source": [
        "### Part (a) -- 7%\n",
        "\n",
        "Write a function `pred` that computes the prediction `y` based on logistic regression, i.e., a single layer with weights `w` and bias `b`. The output is given by: \n",
        "\\begin{equation}\n",
        "y = \\sigma({\\bf w}^T {\\bf x} + b),\n",
        "\\end{equation}\n",
        "where the value of $y$ is an estimate of the probability that the song is released in the current century, namely ${\\rm year} =1$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naY5mT4_zGrD"
      },
      "source": [
        "def pred(w, b, X):\n",
        "  \"\"\"\n",
        "  Returns the prediction `y` of the target based on the weights `w` and scalar bias `b`.\n",
        "\n",
        "  Preconditions: np.shape(w) == (90,)\n",
        "                 type(b) == float\n",
        "                 np.shape(X) = (N, 90) for some N\n",
        "\n",
        "  >>> pred(np.zeros(90), 1, np.ones([2, 90]))\n",
        "  array([0.73105858, 0.73105858]) # It's okay if your output differs in the last decimals\n",
        "  \"\"\"\n",
        "  # Your code goes here \n",
        "\n",
        "  return sigmoid(np.dot(X, w) + b)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxNdmSd3zGrE"
      },
      "source": [
        "### Part (b) -- 7%\n",
        "\n",
        "Write a function `derivative_cost` that computes and returns the gradients \n",
        "$\\frac{\\partial\\mathcal{L}}{\\partial {\\bf w}}$ and\n",
        "$\\frac{\\partial\\mathcal{L}}{\\partial b}$. Here, `X` is the input, `y` is the prediction, and `t` is the true label.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P80bu7qmzGrE"
      },
      "source": [
        "def derivative_cost(X, y, t):\n",
        "  \"\"\"\n",
        "  Returns a tuple containing the gradients dLdw and dLdb.\n",
        "\n",
        "  Precondition: np.shape(X) == (N, 90) for some N\n",
        "                np.shape(y) == (N,)\n",
        "                np.shape(t) == (N,)\n",
        "\n",
        "  Postcondition: np.shape(dLdw) = (90,)\n",
        "           type(dLdb) = float\n",
        "  \"\"\"\n",
        "  # Your code goes here\n",
        "  dldt = t*(1-y) + y*(1-t)\n",
        "  dLdw = np.dot(X.T, dldt) / X.shape[0]\n",
        "  dLdb = np.mean(dldt)\n",
        "  return (dLdw, dLdb)\n"
      ],
      "execution_count": 445,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okPRGM3BjKe2"
      },
      "source": [
        "# **Explenation on Gradients**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHfmPVdsg0eX"
      },
      "source": [
        "**Add here an explaination on how the gradients are computed**:\n",
        "\n",
        "Write your explanation here. Use Latex to write mathematical expressions. [Here is a brief tutorial on latex for notebooks.](https://www.math.ubc.ca/~pwalls/math-python/jupyter/latex/)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhQXAKd4zGrE"
      },
      "source": [
        "### Part (c) -- 7%\n",
        "\n",
        "We can check that our derivative is implemented correctly using the finite difference rule. In 1D, the\n",
        "finite difference rule tells us that for small $h$, we should have\n",
        "\n",
        "$$\\frac{f(x+h) - f(x)}{h} \\approx f'(x)$$\n",
        "\n",
        "Show that $\\frac{\\partial\\mathcal{L}}{\\partial b}$  is implement correctly\n",
        "by comparing the result from `derivative_cost` with the empirical cost derivative computed using the above numerical approximation.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpRTD-fozGrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7da0c120-5d00-4b4b-e49e-10c3a47dd82d"
      },
      "source": [
        "# Your code goes here\n",
        "\n",
        "h = 1e-09\n",
        "\n",
        "t = np.zeros(2,)\n",
        "X = np.ones([2, 90])\n",
        "w = np.zeros(90)\n",
        "b = 1\n",
        "y = pred(w, b, X)\n",
        "y_b_plus = pred(w, b + h, X)\n",
        "\n",
        "cost_y = cost(y, t)\n",
        "cost_y_b_plus = cost(y_b_plus, t)\n",
        "\n",
        "r1 = (cost_y_b_plus - cost_y) / h\n",
        "r2 = derivative_cost(X, y, t)[1]\n",
        "print(\"The analytical results is: \", r1)\n",
        "print(\"The algorithm results is: \", r2)\n",
        "print(\"Gradient difference for w1 (analytical-algorithm): \", r1-r2)\n"
      ],
      "execution_count": 446,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The analytical results is:  0.7310585470321485\n",
            "The algorithm results is:  0.7310585786300049\n",
            "Gradient difference for w1 (analytical-algorithm):  -3.159785644246682e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTiplTPhzGrF"
      },
      "source": [
        "### Part (d) -- 7%\n",
        "\n",
        "Show that $\\frac{\\partial\\mathcal{L}}{\\partial {\\bf w}}$  is implement correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVTsHgnPzGrF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fa44c2f-3375-4edf-c6fe-bdc029540e93"
      },
      "source": [
        "# Your code goes here. You might find this below code helpful: but it's\n",
        "# up to you to figure out how/why, and how to modify the code\n",
        "\n",
        "h = 1e-10\n",
        "t = np.zeros(2,)\n",
        "X1 = np.ones([2, 90]) #+ np.random.randn(2, 90)\n",
        "w1 = np.random.randn(90,) \n",
        "b = 0\n",
        "\n",
        "y1 = pred(w1, b, X1)\n",
        "y1_w1_plus = pred(w1 + h, b, X1)\n",
        "\n",
        "cost_y1 = cost(y1, t)\n",
        "cost_y1_w1_plus = cost(y1_w1_plus, t)\n",
        "\n",
        "r1 = (cost_y1_w1_plus - cost_y1) / h\n",
        "r2 = np.sum(derivative_cost(X1, y1, t)[0])\n",
        "print(\"The analytical results is: \", r1)\n",
        "print(\"The algorithm results is: \", r2)\n",
        "print(\"Gradient difference for w1 (analytical-algorithm): \", r1-r2)\n",
        "print(\"\\n\", '='*200, \"\\n\")\n",
        "\n",
        "# #We can also see for each w:\n",
        "# w2 = np.random.randn(90,) \n",
        "# cost_y2_w2 = np.zeros([90,])\n",
        "# cost_y2_w2_plus = np.zeros([90,])\n",
        "\n",
        "# for i in range(0, len(w1)):\n",
        "#   w2_zeros = np.zeros([90,])\n",
        "#   w2_zeros_plus = np.zeros([90,])\n",
        "#   X_zeros = np.zeros(np.shape(X1))\n",
        "#   X_zeros[:, i] = X1[:, i]\n",
        "#   w2_zeros[i] = w1[i]\n",
        "#   y2 = pred(w2_zeros, b, X_zeros)\n",
        "#   w2_zeros_plus[i] = w1[i] + h\n",
        "#   y2_w2_plus = pred(w2_zeros_plus, b, X_zeros)\n",
        "#   cost_y2_w2[i] = cost(y2, t)\n",
        "#   cost_y2_w2_plus[i] = cost(y2_w2_plus, t)\n",
        "  \n",
        "\n",
        "# y3 = pred(w1, b, X1)\n",
        "\n",
        "# r3 = (cost_y2_w2_plus - cost_y2_w2) / h\n",
        "# r4 = derivative_cost(X1, y3, t)[0]\n",
        "# print(\"The analytical results is:\", r3)\n",
        "# print(\"The algorithm results is: \", r4)\n",
        "# print(\"Gradient difference for w2 (analytical-algorithm): \", r3-r4)"
      ],
      "execution_count": 475,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The analytical results is:  25.116704271965773\n",
            "The algorithm results is:  25.11670129277158\n",
            "Gradient difference for w1 (analytical-algorithm):  2.9791941926760046e-06\n",
            "\n",
            " ======================================================================================================================================================================================================== \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgBTPF_2zGrG"
      },
      "source": [
        "### Part (e) -- 7%\n",
        "\n",
        "Now that you have a gradient function that works, we can actually run gradient descent. \n",
        "Complete the following code that will run stochastic: gradient descent training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nW4DEuuPzGrG"
      },
      "source": [
        "def run_gradient_descent(train_norm_xs, train_ts, val_norm_xs, val_ts, w0, b0, mu=0.1, batch_size=100, max_iters=100):\n",
        "  \"\"\"Return the values of (w, b) after running gradient descent for max_iters.\n",
        "  We use:\n",
        "    - train_norm_xs and train_ts as the training set\n",
        "    - val_norm_xs and val_ts as the test set\n",
        "    - mu as the learning rate\n",
        "    - (w0, b0) as the initial values of (w, b)\n",
        "\n",
        "  Precondition: np.shape(w0) == (90,)\n",
        "                type(b0) == float\n",
        " \n",
        "  Postcondition: np.shape(w) == (90,)\n",
        "                 type(b) == float\n",
        "  \"\"\"\n",
        "  w = w0\n",
        "  b = b0\n",
        "  iter = 0\n",
        "  history = {}\n",
        "  val_cost_history = []\n",
        "  val_acc_history = []\n",
        "\n",
        "  while iter < max_iters:\n",
        "    # shuffle the training set (there is code above for how to do this)\n",
        "    reindex = np.random.permutation(len(train_norm_xs))\n",
        "    train_norm_xs = train_norm_xs[reindex]\n",
        "    train_ts = train_ts[reindex]\n",
        "\n",
        "    for i in range(0, len(train_norm_xs), batch_size): # iterate over each minibatch\n",
        "      # minibatch that we are working with:\n",
        "      X = train_norm_xs[i:(i + batch_size)]\n",
        "      t = train_ts[i:(i + batch_size), 0]\n",
        "\n",
        "      # since len(train_norm_xs) does not divide batch_size evenly, we will skip over\n",
        "      # the \"last\" minibatch\n",
        "      if np.shape(X)[0] != batch_size:\n",
        "        continue\n",
        "\n",
        "      # compute the prediction\n",
        "      prediction = pred(w, b, X)\n",
        "\n",
        "      # update w and b\n",
        "      dLdw, dLdb = derivative_cost(X, t, prediction)\n",
        "      w -= dLdw*mu\n",
        "      b -= dLdb*mu\n",
        "\n",
        "      # increment the iteration count\n",
        "    iter += 1\n",
        "      # compute and print the *validation* loss and accuracy\n",
        "    if (iter % 10 == 0):\n",
        "      val_cost = 0\n",
        "      val_acc = 0\n",
        "      count = 0\n",
        "      for i in range(0, len(val_norm_xs), batch_size): # iterate over each minibatch\n",
        "        # minibatch that we are working with:\n",
        "        X = val_norm_xs[i:(i + batch_size)]\n",
        "        t = val_ts[i:(i + batch_size), 0]\n",
        "\n",
        "        val_prediction = pred(w, b, X)\n",
        "        val_cost += cost(t, val_prediction)\n",
        "        val_acc += get_accuracy(t, val_prediction)\n",
        "        count += 1\n",
        "\n",
        "      val_cost /= count\n",
        "      val_acc /= count\n",
        "      print(\"Iter %d. [Val Acc %.0f%%, Loss %f]\" % (\n",
        "              iter, val_acc * 100, val_cost))\n",
        "      val_cost_history.append(val_cost)\n",
        "      val_acc_history.append(val_acc)\n",
        "\n",
        "      if iter >= max_iters:\n",
        "        break\n",
        "\n",
        "      # Think what parameters you should return for further use\n",
        "  history[\"val_cost\"] = val_cost_history\n",
        "  history[\"val_acc\"] = val_acc_history\n",
        "  return history, (w, b)\n",
        "\n"
      ],
      "execution_count": 476,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MqzT0jGzGrH"
      },
      "source": [
        "### Part (f) -- 7%\n",
        "\n",
        "Call `run_gradient_descent` with the weights and biases all initialized to zero.\n",
        "Show that if the learning rate $\\mu$ is too small, then convergence is slow.\n",
        "Also, show that if $\\mu$ is too large, then the optimization algorirthm does not converge. The demonstration should be made using plots showing these effects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE32Iqo6zGrH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdddc3c0-f34e-49be-abf7-0ed09f2dcf92"
      },
      "source": [
        "w0 = np.random.randn(90)\n",
        "b0 = np.random.randn(1)[0]\n",
        "\n",
        "# Write your code here\n",
        "print(\"Small mu: \")\n",
        "small_mu_history, parameters_small = run_gradient_descent(train_norm_xs, train_ts, val_norm_xs, val_ts, w0, b0, mu=5e-4, batch_size=100, max_iters=300)\n",
        "print(\"\\n\\n\", '='*200, \"\\n\\nLarge mu: \")\n",
        "large_mu_history, parameters_large = run_gradient_descent(train_norm_xs, train_ts, val_norm_xs, val_ts, w0, b0, mu=1e+4, batch_size=100, max_iters=300)\n"
      ],
      "execution_count": 486,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Small mu: \n",
            "Iter 10. [Val Acc 0%, Loss 18.243321]\n",
            "Iter 20. [Val Acc 0%, Loss 19.157767]\n",
            "Iter 30. [Val Acc 0%, Loss 19.774538]\n",
            "Iter 40. [Val Acc 0%, Loss 20.268667]\n",
            "Iter 50. [Val Acc 0%, Loss 20.577954]\n",
            "Iter 60. [Val Acc 0%, Loss 20.738114]\n",
            "Iter 70. [Val Acc 0%, Loss 20.700245]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 80. [Val Acc 0%, Loss 20.644097]\n",
            "Iter 90. [Val Acc 0%, Loss 20.625727]\n",
            "Iter 100. [Val Acc 0%, Loss 20.613899]\n",
            "Iter 110. [Val Acc 0%, Loss 20.607605]\n",
            "Iter 120. [Val Acc 0%, Loss 20.604821]\n",
            "Iter 130. [Val Acc 1%, Loss 20.602719]\n",
            "Iter 140. [Val Acc 1%, Loss 20.599910]\n",
            "Iter 150. [Val Acc 1%, Loss 20.595280]\n",
            "Iter 160. [Val Acc 1%, Loss 20.592653]\n",
            "Iter 170. [Val Acc 1%, Loss 20.595081]\n",
            "Iter 180. [Val Acc 1%, Loss 20.597369]\n",
            "Iter 190. [Val Acc 1%, Loss 20.600959]\n",
            "Iter 200. [Val Acc 1%, Loss 20.603558]\n",
            "Iter 210. [Val Acc 1%, Loss 20.606179]\n",
            "Iter 220. [Val Acc 1%, Loss 20.608709]\n",
            "Iter 230. [Val Acc 1%, Loss 20.611080]\n",
            "Iter 240. [Val Acc 1%, Loss 20.612497]\n",
            "Iter 250. [Val Acc 1%, Loss 20.613881]\n",
            "Iter 260. [Val Acc 1%, Loss 20.615719]\n",
            "Iter 270. [Val Acc 1%, Loss 20.616863]\n",
            "Iter 280. [Val Acc 2%, Loss 20.618083]\n",
            "Iter 290. [Val Acc 2%, Loss 20.619129]\n",
            "Iter 300. [Val Acc 2%, Loss 20.620420]\n",
            "\n",
            "\n",
            " ======================================================================================================================================================================================================== \n",
            "\n",
            "Large mu: \n",
            "Iter 10. [Val Acc 43%, Loss 20.626341]\n",
            "Iter 20. [Val Acc 43%, Loss 20.625620]\n",
            "Iter 30. [Val Acc 43%, Loss 20.625620]\n",
            "Iter 40. [Val Acc 43%, Loss 20.625620]\n",
            "Iter 50. [Val Acc 43%, Loss 20.625620]\n",
            "Iter 60. [Val Acc 43%, Loss 20.626341]\n",
            "Iter 70. [Val Acc 43%, Loss 20.626341]\n",
            "Iter 80. [Val Acc 43%, Loss 20.626341]\n",
            "Iter 90. [Val Acc 43%, Loss 20.626341]\n",
            "Iter 100. [Val Acc 43%, Loss 20.626341]\n",
            "Iter 110. [Val Acc 43%, Loss 20.626341]\n",
            "Iter 120. [Val Acc 43%, Loss 20.625620]\n",
            "Iter 130. [Val Acc 43%, Loss 20.625620]\n",
            "Iter 140. [Val Acc 43%, Loss 20.626341]\n",
            "Iter 150. [Val Acc 43%, Loss 20.625620]\n",
            "Iter 160. [Val Acc 43%, Loss 20.626341]\n",
            "Iter 170. [Val Acc 43%, Loss 20.626341]\n",
            "Iter 180. [Val Acc 43%, Loss 20.626341]\n",
            "Iter 190. [Val Acc 43%, Loss 20.626341]\n",
            "Iter 200. [Val Acc 43%, Loss 20.626341]\n",
            "Iter 210. [Val Acc 43%, Loss 20.625620]\n",
            "Iter 220. [Val Acc 43%, Loss 20.625620]\n",
            "Iter 230. [Val Acc 43%, Loss 20.625620]\n",
            "Iter 240. [Val Acc 43%, Loss 20.625620]\n",
            "Iter 250. [Val Acc 43%, Loss 20.625620]\n",
            "Iter 260. [Val Acc 43%, Loss 20.625620]\n",
            "Iter 270. [Val Acc 43%, Loss 20.625620]\n",
            "Iter 280. [Val Acc 43%, Loss 20.625620]\n",
            "Iter 290. [Val Acc 43%, Loss 20.625620]\n",
            "Iter 300. [Val Acc 43%, Loss 20.625620]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "def plot_acc_loss(acc_history, loss_history, iteration_resolution):\n",
        "  \"\"\"Plot the values of validation accuracy and loss from model train history lists.\n",
        "  We use:\n",
        "    - acc_historys as the accuracy history list\n",
        "    - loss_history as the loss history list\n",
        "    - iteration_resolution as the values iterations resolution\n",
        "\n",
        "  Precondition: type(acc_history) == list(flaot)\n",
        " \n",
        "  Postcondition: type(loss_history) == list(flaot)\n",
        "  \"\"\"\n",
        "  iterations = range(iteration_resolution, len(acc_history)*iteration_resolution + iteration_resolution, 10)\n",
        "  \n",
        "  plt.figure(figsize=[20,4])\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(iterations[:], acc_history[:], \"b-\")\n",
        "  plt.xlabel(\"iteration\", fontsize=14)\n",
        "  plt.ylabel(\"Validation Accuracy\", rotation=90, fontsize=14)\n",
        "  ax1 = plt.gca()\n",
        "  ax1.set(ylim=(max(acc_history) - 0.1, max(acc_history) + 0.1))\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "  plt.figure(figsize=[20,4])\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(iterations[:], loss_history[:], \"r-\")\n",
        "  plt.xlabel(\"iteration\", fontsize=14)\n",
        "  plt.ylabel(\"Validation Loss\", rotation=90, fontsize=14)\n",
        "  ax2 = plt.gca()\n",
        "  ax2.set(ylim=(min(loss_history) - 0.2, max(loss_history) +0.2))\n",
        "  plt.grid()\n",
        "  plt.show()\n"
      ],
      "metadata": {
        "id": "3BGW2webqpY9"
      },
      "execution_count": 482,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_acc_loss(small_mu_history[\"val_acc\"], small_mu_history[\"val_cost\"], 10)"
      ],
      "metadata": {
        "id": "4Ng2E7nTvtvw",
        "outputId": "abbdd11f-31f8-4c98-97ba-b455e8bd57bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "execution_count": 483,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_acc_loss(large_mu_history[\"val_acc\"], large_mu_history[\"val_cost\"], 10)\n"
      ],
      "metadata": {
        "id": "NvXTevDK18rY",
        "outputId": "f7717e9d-9ca4-4b47-fb5f-14d98206f865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "execution_count": 484,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S44GmUZ12o-g"
      },
      "source": [
        "**Explain and discuss your results here:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ5HlDFAzGrH"
      },
      "source": [
        "### Part (g) -- 7%\n",
        "\n",
        "Find the optimial value of ${\\bf w}$ and $b$ using your code. Explain how you chose\n",
        "the learning rate $\\mu$ and the batch size. Show plots demostrating good and bad behaviours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dFOFSwgzGrI"
      },
      "source": [
        "w0 = np.random.randn(90)\n",
        "b0 = np.random.randn(1)[0]\n",
        "\n",
        "# Write your code here\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkZt7_932zX2"
      },
      "source": [
        "**Explain and discuss your results here:**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KrQqSj2zGrI"
      },
      "source": [
        "### Part (h) -- 15%\n",
        "\n",
        "Using the values of `w` and `b` from part (g), compute your training accuracy, validation accuracy,\n",
        "and test accuracy. Are there any differences between those three values? If so, why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuKw2mLozGrI"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "train_acc = ...\n",
        "val_acc = ...\n",
        "test_acc = ...\n",
        "\n",
        "print('train_acc = ', train_acc, ' val_acc = ', val_acc, ' test_acc = ', test_acc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXZa1u6920M3"
      },
      "source": [
        "**Explain and discuss your results here:**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4eP2Yh1zGrI"
      },
      "source": [
        "### Part (i) -- 15%\n",
        "\n",
        "Writing a classifier like this is instructive, and helps you understand what happens when\n",
        "we train a model. However, in practice, we rarely write model building and training code\n",
        "from scratch. Instead, we typically use one of the well-tested libraries available in a package.\n",
        "\n",
        "Use `sklearn.linear_model.LogisticRegression` to build a linear classifier, and make predictions about the test set. Start by reading the\n",
        "[API documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
        "\n",
        "Compute the training, validation and test accuracy of this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24LCfAa1zGrJ"
      },
      "source": [
        "import sklearn.linear_model\n",
        "\n",
        "model = ...\n",
        "\n",
        "train_acc = ...\n",
        "val_acc = ...\n",
        "test_acc = ...\n",
        "\n",
        "print('train_acc = ', train_acc, ' val_acc = ', val_acc, ' test_acc = ', test_acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRqucdV923tG"
      },
      "source": [
        "**This parts helps by checking if the code worked.**\n",
        "**Check if you get similar results, if not repair your code**\n"
      ]
    }
  ]
}